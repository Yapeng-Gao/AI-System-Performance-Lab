# Module A: CUDA åŸºç¡€æ¶æ„

æœ¬ç›®å½•åŒ…å« CUDA æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ„ç›¸å…³çš„ç¤ºä¾‹ä»£ç ï¼Œæ˜¯ã€ŠAI ç³»ç»Ÿæ€§èƒ½å·¥ç¨‹ã€‹ä¸“æ  Module A çš„é…å¥—å®æˆ˜ä»£ç ã€‚

## ğŸ“š ç›®å½•

| ç« èŠ‚ | æ–‡ä»¶ | æ ¸å¿ƒå†…å®¹ | çŸ¥è¯†ç‚¹ |
|------|------|----------|--------|
| **ç¬¬ 1 ç« ** | `01_hello_modern.cu` | CUDA æ ¸å¿ƒæ¦‚å¿µæ€»è§ˆ | Grid-Block-Thread æ¨¡å‹ã€é”™è¯¯æ£€æŸ¥ã€å¼‚æ­¥æ‰§è¡Œã€Unified Memory |
| **ç¬¬ 2 ç« ** | `02_hardware_query.cu` | GPU ç¡¬ä»¶æ¶æ„æ·±åº¦è§£æ | SM æ¶æ„ã€å†…å­˜å±‚æ¬¡ã€L2 Cacheã€Tensor Core èƒ½åŠ›ã€å¸¦å®½åˆ†æ |
| **ç¬¬ 3 ç« ** | `03_grid_mapping.cu` | CUDA ç¼–ç¨‹æ¨¡å‹ç‰©ç†æ˜ å°„ | GigaThread Engine è°ƒåº¦ã€SM æ˜ å°„ã€Wavefront æ•ˆåº”ã€PTX å†…è”æ±‡ç¼– |
| **ç¬¬ 4 ç« ** | `04_warp_divergence.cu` | çº¿ç¨‹è°ƒåº¦ï¼šSIMT, Divergence ä¸ Replay | Warp å‘æ•£ã€Bank Conflictã€æŒ‡ä»¤é‡æ’­ã€æ€§èƒ½é‡åŒ– |
| **ç¬¬ 5 ç« ** | `05_kernel_structure.cu` | Kernel ç»“æ„ä¸ ABI åˆ†æ | ç»“æ„ä½“å¯¹é½é™·é˜±ã€å‡½æ•°å†…è”æ§åˆ¶ã€Launch Bounds ä¼˜åŒ– |
| **ç¬¬ 6 ç« ** | `06_nvrtc_jit.cpp` | NVRTC è¿è¡Œæ—¶ç¼–è¯‘ä¸ Driver API | è¿è¡Œæ—¶ç‰¹åŒ–ã€PTX åŠ¨æ€åŠ è½½ã€æ¶æ„è‡ªé€‚åº” |
| **ç¬¬ 7 ç« ** | `07_memory_spaces.cu` | å†…å­˜æ¨¡å‹å…¨æ™¯ | åœ°å€ç©ºé—´æ¢æµ‹ã€UVA Zero-Copyã€Local Memory Spillingã€__restrict__ ä¼˜åŒ– |
| **ç¬¬ 8 ç« ** | `08_async_pipeline.cu` | å¼‚æ­¥æ‰§è¡Œæ¨¡å‹ | Pinned Memoryã€å¤š Stream å¹¶å‘ã€Depth-First è°ƒåº¦ã€æµæ°´çº¿ Overlap |
| **ç¬¬ 9 ç« ** | `09_debug_and_sanitizer.cu` | è°ƒè¯•ä¸é”™è¯¯è¯Šæ–­ | Compute Sanitizerã€å†…å­˜è¶Šç•Œæ£€æµ‹ã€æ•°æ®ç«äº‰æ£€æµ‹ã€éæ³•åŒæ­¥æ£€æµ‹ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¼–è¯‘æ„å»º

#### Linux ç¯å¢ƒ
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --parallel 8
```

#### Windows/CLion ç¯å¢ƒ
- ä½¿ç”¨ CLion ç›´æ¥æ„å»ºï¼ˆæ„å»ºè¾“å‡ºåœ¨ `cmake-build-debug` æˆ– `cmake-build-debug-visual-studio` ç›®å½•ï¼‰
- æˆ–æ‰‹åŠ¨æ„å»ºï¼š
```powershell
mkdir build
cd build
cmake .. -G "Visual Studio 17 2022" -A x64
cmake --build . --parallel 8
```

### è¿è¡Œç¤ºä¾‹

ç¼–è¯‘æˆåŠŸåï¼Œå¯æ‰§è¡Œæ–‡ä»¶ä½ç½®ï¼š
- **Linux**: `build/bin/` ç›®å½•
- **Windows/CLion**: `cmake-build-debug/bin/` æˆ– `cmake-build-debug-visual-studio/bin/` ç›®å½•

```bash
# Linux: åœ¨ build ç›®å½•ä¸‹è¿è¡Œ
./bin/01_cuda_basics_01_hello_modern
./bin/01_cuda_basics_02_hardware_query
./bin/01_cuda_basics_03_grid_mapping
./bin/01_cuda_basics_04_warp_divergence
./bin/01_cuda_basics_05_kernel_structure
./bin/01_cuda_basics_06_nvrtc_jit
./bin/01_cuda_basics_07_memory_spaces
./bin/01_cuda_basics_08_async_pipeline
./bin/01_cuda_basics_09_debug_and_sanitizer

# Windows/CLion: åœ¨ cmake-build-debug/bin ç›®å½•ä¸‹è¿è¡Œ
# æˆ–åœ¨ PowerShell ä¸­ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•ï¼‰
.\cmake-build-debug\bin\01_cuda_basics_01_hello_modern.exe
.\cmake-build-debug\bin\01_cuda_basics_06_nvrtc_jit.exe
.\cmake-build-debug\bin\01_cuda_basics_07_memory_spaces.exe
.\cmake-build-debug\bin\01_cuda_basics_08_async_pipeline.exe
.\cmake-build-debug\bin\01_cuda_basics_09_debug_and_sanitizer.exe
```

---

## ğŸ“– å„ç« è¯¦ç»†è¯´æ˜

### ç¬¬ 1 ç« ï¼šCUDA æ ¸å¿ƒæ¦‚å¿µæ€»è§ˆ (`01_hello_modern.cu`)

**ç°ä»£ç‰ˆ Hello World**ï¼šå±•ç¤º CUDA 12+ çš„å·¥ç¨‹è§„èŒƒå’Œç”Ÿäº§çº§ä»£ç ç‰¹å¾ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **å®å®šä¹‰å°è£…**ï¼šä½¿ç”¨ `CUDA_CHECK` å®åŒ…è£¹æ‰€æœ‰ CUDA API è°ƒç”¨ï¼Œç¡®ä¿åœ¨å‡ºé”™æ—¶èƒ½æ‰“å°å…·ä½“çš„æ–‡ä»¶åå’Œè¡Œå·ï¼Œå¹¶å®‰å…¨é€€å‡ºã€‚è¿™ç§ Fail Fast ç­–ç•¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è‡³å…³é‡è¦ã€‚

2. **ç¡¬ä»¶æ„ŸçŸ¥**ï¼šåœ¨ Kernel å†…éƒ¨é€šè¿‡ `__CUDA_ARCH__` å®åˆ¤æ–­å½“å‰ç¡¬ä»¶æ¶æ„ï¼ˆç¼–è¯‘æœŸå¸¸é‡ï¼‰ï¼ŒåŒæ—¶åœ¨ Host ç«¯ä½¿ç”¨ `cudaGetDeviceProperties` è¿›è¡Œè¿è¡Œæ—¶ç¡¬ä»¶æŸ¥è¯¢ã€‚

3. **å¼‚æ­¥æ‰§è¡Œä¸åŒæ­¥**ï¼šæ¼”ç¤º Kernel å¯åŠ¨çš„å¼‚æ­¥ç‰¹æ€§ï¼Œä»¥åŠ `cudaGetLastError()` å’Œ `cudaDeviceSynchronize()` çš„æ­£ç¡®ä½¿ç”¨ã€‚

4. **ç»Ÿä¸€å†…å­˜ç®¡ç†**ï¼šä½¿ç”¨ `cudaMallocManaged` ç®€åŒ–å†…å­˜åˆ†é…ï¼Œæ•°æ®ä¼šåœ¨ CPU/GPU é—´è‡ªåŠ¨æŒ‰éœ€è¿ç§»ï¼ˆPage Migrationï¼‰ã€‚

5. **çº¿ç¨‹ç´¢å¼•è®¡ç®—**ï¼šå±•ç¤º CUDA çš„ Grid-Block-Thread ä¸‰å±‚æ‰§è¡Œæ¨¡å‹ï¼Œé€šè¿‡ `global_id = blockIdx.x * blockDim.x + threadIdx.x` è®¡ç®—å…¨å±€çº¿ç¨‹ç´¢å¼•ã€‚

#### é¢„æœŸè¾“å‡º

```
[Host] Starting Modern CUDA Hello World...
[Host] GPU Name: NVIDIA GeForce RTX 4090
[Host] SM Count: 128
[Host] Compute Capability: 8.9
[Host] Launching Kernel...
[Device] Kernel running on SM arch sm_890
[Device] GridDim=1, BlockDim=32
[Host] Verifying results...
[Host] Verification PASSED! [OK]
```

#### äºŒè¿›åˆ¶åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `01_fatbin_inspect.sh` è„šæœ¬ï¼Œåˆ©ç”¨ `cuobjdump` å·¥å…·åˆ†æç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼š

```bash
cd examples/01_cuda_basics
bash 01_fatbin_inspect.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼š
- **Windows/CLion**: `cmake-build-debug/bin` æˆ– `cmake-build-debug-visual-studio/bin`
- **Linux**: `build/bin`

è¯¥è„šæœ¬å¯ä»¥å±•ç¤ºï¼š
- **PTXï¼ˆè™šæ‹Ÿæ¶æ„ï¼‰**ï¼šä¸­é—´è¡¨ç¤ºä»£ç ï¼Œç”±é©±åŠ¨ç¨‹åºåœ¨è¿è¡Œæ—¶ JIT ç¼–è¯‘åˆ°ç›®æ ‡æ¶æ„
- **SASSï¼ˆçœŸå®æ¶æ„ï¼‰**ï¼šå®é™…è¿è¡Œåœ¨ GPU ä¸Šçš„æœºå™¨ç 

è¿™å¯ä»¥éªŒè¯ CMake é…ç½®ä¸­çš„ `CMAKE_CUDA_ARCHITECTURES` æ˜¯å¦ç”Ÿæ•ˆã€‚

---

### ç¬¬ 2 ç« ï¼šGPU ç¡¬ä»¶æ¶æ„æ·±åº¦è§£æ (`02_hardware_query.cu`)

**ç¡¬ä»¶æ‹“æ‰‘ä¾¦æ¢**ï¼šæŒ–æ˜ SM æ¶æ„ã€L2 Cacheã€Tensor Core èƒ½åŠ›ä¸å¸¦å®½æé™ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **è®¡ç®—èƒ½åŠ›ä¸æ¶æ„è¯†åˆ«**ï¼šæ ¹æ® Compute Capability è¯†åˆ« GPU æ¶æ„ï¼ˆHopperã€Ampereã€Volta ç­‰ï¼‰ï¼Œå¹¶æ¨ç®—æ¯ä¸ª SM çš„ CUDA Core æ•°é‡ã€‚

2. **SM å®è§‚æ‹“æ‰‘**ï¼šå±•ç¤ºå¤šå¤„ç†å™¨æ•°é‡ã€CUDA Core æ€»æ•°ç­‰å®è§‚è®¡ç®—èµ„æºã€‚

3. **å†…å­˜ä½“ç³»åˆ†æ**ï¼š
   - å…¨å±€å†…å­˜å®¹é‡ï¼ˆHBM/DDRï¼‰
   - å†…å­˜æ€»çº¿å®½åº¦
   - ç†è®ºå³°å€¼å¸¦å®½è®¡ç®—
   - **L2 Cache å¤§å°**ï¼ˆå…³é”®æ€§èƒ½æŒ‡æ ‡ï¼Œå½±å“æ•°æ®é©»ç•™æ§åˆ¶ï¼‰

4. **SM å¾®æ¶æ„èµ„æº**ï¼ˆOccupancy åˆ†æå…³é”®ï¼‰ï¼š
   - Shared Memory é™åˆ¶ï¼ˆæ¯ Block å’ŒåŠ¨æ€åˆ†é…ï¼‰
   - å¯„å­˜å™¨æ•°é‡é™åˆ¶
   - çº¿ç¨‹æ•°é™åˆ¶ï¼ˆæ¯ Block å’Œæ¯ SMï¼‰
   - Warp å¤§å°

5. **ç°ä»£ç‰¹æ€§æ”¯æŒä¾¦æµ‹**ï¼š
   - Unified Addressing (UVA)
   - Managed Memory (Page Migration)
   - TMA (Tensor Memory Accelerator) - Hopper æ¶æ„
   - Thread Block Clusters - Hopper æ¶æ„

#### é¢„æœŸè¾“å‡º

```
=================================================================
   AI System Performance Lab - Hardware Topology Detective   
=================================================================
Detected 1 CUDA Capable Device(s)

[Device 0]: NVIDIA GeForce RTX 4090
-----------------------------------------------------------------
  [Architecture]
    Compute Capability      : 8.9 (Ampere / Ada class)
  [Compute Topology]
    Multiprocessors (SMs)   : 128
    CUDA Cores / SM         : 128
    Total CUDA Cores        : 16384
    GPU Clock Rate          : N/A (removed in CUDA 12+)
  [Memory Hierarchy]
    Global Memory (HBM/DDR) : 24.00 GB
    Memory Bus Width        : 384-bit
    Memory Clock Rate       : N/A (removed in CUDA 12+)
    Theoretical Bandwidth   : N/A (use nvml API for accurate value)
    L2 Cache Size           : 72.00 MB (Key for residency control)
  [SM Micro-Architecture]
    Max Shared Mem / Block  : 48.00 KB
    Max Shared Mem (Opt-in) : 164.00 KB (Dynamic)
    Max Registers / Block   : 65536
    Max Threads / Block     : 1024
    Max Threads / SM        : 1536
    Warp Size               : 32
  [Modern Features Support]
    Unified Addressing      : Yes
    Managed Memory          : Yes
    TMA (Tensor Mem Accel)  : No
    Thread Block Clusters   : No
```

#### æ³¨æ„äº‹é¡¹

- åœ¨ CUDA 12+ ç‰ˆæœ¬ä¸­ï¼Œ`clockRate` å’Œ `memoryClockRate` å­—æ®µå·²è¢«ç§»é™¤ï¼Œä»£ç ä½¿ç”¨æ¡ä»¶ç¼–è¯‘å…¼å®¹æ–°æ—§ç‰ˆæœ¬ã€‚
- å¦‚éœ€è·å–å‡†ç¡®çš„æ—¶é’Ÿé¢‘ç‡å’Œå¸¦å®½ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ NVML (NVIDIA Management Library) APIã€‚

---

### ç¬¬ 3 ç« ï¼šCUDA ç¼–ç¨‹æ¨¡å‹ç‰©ç†æ˜ å°„ (`03_grid_mapping.cu`)

**Grid Mapper**ï¼šå¯è§†åŒ– GigaThread Engine çš„è°ƒåº¦é€»è¾‘ä¸ç‰©ç† SM æ˜ å°„ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **PTX å†…è”æ±‡ç¼–**ï¼šä½¿ç”¨ `asm volatile("mov.u32 %0, %smid;")` ç›´æ¥è¯»å–ç¡¬ä»¶ç‰¹æ®Šå¯„å­˜å™¨ `%smid`ï¼Œè·å– Block å®é™…è¿è¡Œçš„ç‰©ç† SM IDã€‚è¿™æ˜¯æ¯” CUDA C++ API æ›´åº•å±‚çš„æ“ä½œï¼Œå…¼å®¹æ‰€æœ‰æ¶æ„ã€‚

2. **æ‰§è¡Œé¡ºåºè¿½è¸ª**ï¼šé€šè¿‡ Global Atomic æ“ä½œï¼ˆ`atomicAdd`ï¼‰è¿½è¸ª Block çš„çœŸå®æ‰§è¡Œé¡ºåºï¼ˆExecution Orderï¼‰ï¼ŒéªŒè¯ GigaThread Engine çš„è°ƒåº¦ç­–ç•¥ã€‚

3. **Wavefront æ•ˆåº”è§‚å¯Ÿ**ï¼š
   - é€šè¿‡æ¨¡æ‹Ÿè®¡ç®—è´Ÿè½½ï¼ˆBusy Waitï¼‰æ‹‰é•¿ Block æ‰§è¡Œæ—¶é—´
   - è§‚å¯Ÿå¤šæ³¢æ¬¡ï¼ˆWaveï¼‰è°ƒåº¦æ¨¡å¼
   - æ£€æµ‹å°¾éƒ¨æ•ˆåº”ï¼ˆTail Effectï¼‰ï¼šæœ€åä¸€ä¸ª Block å¯èƒ½ç‹¬å  GPU

4. **è´Ÿè½½å‡è¡¡åˆ†æ**ï¼š
   - ç»Ÿè®¡æ¯ä¸ª SM å¤„ç†çš„ Block æ•°é‡
   - éªŒè¯ Round-Robin åˆ†é…ç­–ç•¥
   - å¯è§†åŒ– Block ID åˆ° SM ID çš„æ˜ å°„å…³ç³»

#### é¢„æœŸè¾“å‡º

```
[Host] Starting Grid Scheduler Tracer...
[Host] GPU: NVIDIA GeForce RTX 4090, Total SMs: 128
[Host] Launching 2561 Blocks (approx 2560 full waves + 1 tail)

[Analysis 1] SM Load Balance (Top 5 & Bottom 5):
  SM 00 processed 20 blocks
  SM 01 processed 20 blocks
  ...

[Analysis 2] Tail Effect Detection:
  The very last block to run was logical Block 2560
  It ran on physical SM 0
  Note: While this block was running, other SMs might have been IDLE if the grid size wasn't aligned to waves.

[Visualizer] Logical Block ID -> Physical SM ID (First 64 Blocks):
  Blocks 000-015:   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
  ...

[Conclusion] GigaThread Engine successfully distributed work across ALL 128 SMs. âœ…
```

#### æŠ€æœ¯ç»†èŠ‚

- **SM ID è¯»å–**ï¼šä½¿ç”¨ PTX æ±‡ç¼–ç›´æ¥è®¿é—®ç¡¬ä»¶å¯„å­˜å™¨ï¼Œæ¯”è½¯ä»¶ API æ›´åº•å±‚ã€æ›´å‡†ç¡®
- **åŸå­æ“ä½œ**ï¼š`atomicAdd` ä¿è¯æ‰§è¡Œé¡ºåºçš„å…¨å±€ä¸€è‡´æ€§ï¼Œç”¨äºè¿½è¸ªè°ƒåº¦é¡ºåº
- **æ—¶é’Ÿè®¡æ•°**ï¼šä½¿ç”¨ `clock64()` è®°å½• Block å¯åŠ¨æ—¶é—´æˆ³ï¼Œå¯ç”¨äºåˆ†æè°ƒåº¦å»¶è¿Ÿ

---

### ç¬¬ 4 ç« ï¼šçº¿ç¨‹è°ƒåº¦ï¼šSIMT, Divergence ä¸ Replay (`04_warp_divergence.cu`)

**Micro-benchmark**ï¼šé‡åŒ–åˆ†æ”¯å‘æ•£ä¸ Shared Memory Bank Conflict çš„ç‰©ç†ä»£ä»·ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Warp Divergenceï¼ˆåˆ†æ”¯å‘æ•£ï¼‰**ï¼š
   - **Baseline æ¨¡å¼**ï¼šæ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒè·¯å¾„ï¼ŒSIMT å•å…ƒæ»¡è½½è¿è¡Œ
   - **Divergent æ¨¡å¼**ï¼šå¥‡å¶çº¿ç¨‹èµ°ä¸åŒåˆ†æ”¯ï¼Œç¡¬ä»¶ä¸²è¡ŒåŒ–æ‰§è¡Œï¼ˆå…ˆæ‰§è¡Œå¶æ•°çº¿ç¨‹ï¼Œå†æ‰§è¡Œå¥‡æ•°çº¿ç¨‹ï¼‰
   - **æ€§èƒ½å½±å“**ï¼šç†è®ºååé‡å‡åŠï¼ˆç†æƒ³æƒ…å†µ 2.0x æ€§èƒ½æŸå¤±ï¼‰

2. **Bank Conflictï¼ˆå­˜å‚¨ä½“å†²çªï¼‰**ï¼š
   - **æ— å†²çªè®¿é—®**ï¼šStride=1ï¼Œ32 ä¸ªçº¿ç¨‹è®¿é—®ä¸åŒ Bankï¼Œ1 ä¸ªå‘¨æœŸå®Œæˆ
   - **32-way å†²çª**ï¼šStride=32ï¼Œæ‰€æœ‰çº¿ç¨‹è®¿é—®åŒä¸€ Bankï¼ŒæŒ‡ä»¤é‡æ’­ 32 æ¬¡
   - **æ€§èƒ½å½±å“**ï¼šç†è®ºå»¶è¿Ÿå¢åŠ  32 å€ï¼ˆç†æƒ³æƒ…å†µ 32.0x æ€§èƒ½æŸå¤±ï¼‰

3. **æ€§èƒ½æµ‹é‡æŠ€æœ¯**ï¼š
   - ä½¿ç”¨ `clock64()` è¿›è¡Œé«˜ç²¾åº¦å‘¨æœŸè®¡æ•°
   - é€šè¿‡ `#pragma unroll` å‡å°‘å¾ªç¯å¼€é”€ï¼Œçªå‡ºè¢«æµ‹æ“ä½œ
   - ä½¿ç”¨ `volatile` é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰å†…å­˜è®¿é—®

4. **ç¼–è¯‘å™¨ä¼˜åŒ–é˜²æŠ¤**ï¼š
   - ä½¿ç”¨ `volatile` å˜é‡é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–
   - é€šè¿‡æ­»ä»£ç è·¯å¾„ï¼ˆ`if (val == 999999.0f)`ï¼‰é˜²æ­¢æ­»ä»£ç æ¶ˆé™¤

#### é¢„æœŸè¾“å‡º

```
=================================================================
   AI System Performance Lab - SIMT & Replay Analyzer   
=================================================================
Running on GPU: NVIDIA GeForce RTX 4090 (Arch sm_89)

[Experiment 1] Measuring Warp Divergence Cost (ALU)
  Baseline (No Branch) Cycles : 2000
  Divergent (If-Else) Cycles  : 4000
  >> Performance Penalty      : 2.00x Slower (Ideal: 2.0x)

[Experiment 2] Measuring Instruction Replay Cost (Shared Mem)
  Linear Access (No Conflict) : 1000 cycles
  Stride-32 (32-way Conflict) : 32000 cycles
  >> Replay Penalty           : 32.00x Slower (Ideal: 32.0x)

Note: 'Ideal' assumes pure isolation. Real hardware pipelines may hide some latency.
```

#### å®éªŒè®¾è®¡

- **å®éªŒ 1ï¼šMath Divergence**
  - å¯¹æ¯”æ— åˆ†æ”¯ä»£ç  vs å¥‡å¶åˆ†æ”¯ä»£ç 
  - éªŒè¯ ALU åˆ©ç”¨ç‡å‡åŠï¼ˆSIMT ä¸²è¡ŒåŒ–ï¼‰
  - ä½¿ç”¨æµ®ç‚¹è¿ç®—åˆ¶é€ è®¡ç®—è´Ÿè½½

- **å®éªŒ 2ï¼šBank Conflict Replay**
  - å¯¹æ¯”æ— å†²çªè®¿é—® vs 32-way Bank Conflict
  - éªŒè¯æŒ‡ä»¤é‡æ’­æœºåˆ¶
  - ä½¿ç”¨ Shared Memory è¯»åå†™æ“ä½œåˆ¶é€ ä¾èµ–é“¾

#### æ³¨æ„äº‹é¡¹

- å®é™…ç¡¬ä»¶æµæ°´çº¿å¯èƒ½ä¼šéšè—éƒ¨åˆ†å»¶è¿Ÿï¼Œå› æ­¤å®æµ‹å€¼å¯èƒ½ç•¥ä½äºç†æƒ³å€¼
- `clock64()` è¿”å›çš„æ˜¯ SM æ—¶é’Ÿå‘¨æœŸï¼Œä¸æ˜¯ç»å¯¹æ—¶é—´
- å¾ªç¯æ¬¡æ•°ï¼ˆ`PER_KERNEL_ITERS`ï¼‰éœ€è¦è¶³å¤Ÿå¤§ä»¥æ‘Šè–„æµ‹é‡å¼€é”€ï¼Œä½†ä¸è¦è§¦å‘ TDRï¼ˆè¶…æ—¶æ£€æµ‹ä¸æ¢å¤ï¼‰

---

---

### ç¬¬ 5 ç« ï¼šKernel ç»“æ„ä¸ ABI åˆ†æ (`05_kernel_structure.cu`)

**ABI æ·±åº¦è§£æ**ï¼šæ­ç¤º Host-Device è¾¹ç•Œä¸Šçš„é™·é˜±ä¸ä¼˜åŒ–æŠ€å·§ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **ç»“æ„ä½“å¯¹é½é™·é˜±**ï¼š
   - Host ç¼–è¯‘å™¨ï¼ˆGCC/MSVCï¼‰å’Œ Device ç¼–è¯‘å™¨ï¼ˆNVCCï¼‰å¯èƒ½é‡‡ç”¨ä¸åŒçš„ Padding ç­–ç•¥
   - `__align__` å…³é”®å­—å¼ºåˆ¶å¯¹é½ï¼Œé¿å…ç»“æ„ä½“å¸ƒå±€ä¸ä¸€è‡´å¯¼è‡´çš„ Bug
   - æ¼”ç¤ºä¸åŒå¯¹é½ç­–ç•¥å¯¹å†…å­˜å¸ƒå±€çš„å½±å“

2. **å‡½æ•°å†…è”æ§åˆ¶**ï¼š
   - `__noinline__`ï¼šå¼ºåˆ¶å‡½æ•°ä¸è¢«å†…è”ï¼Œç”¨äºè°ƒè¯•å’Œ ABI åˆ†æ
   - `__forceinline__`ï¼šå¼ºåˆ¶å†…è”ï¼Œæ¶ˆé™¤å‡½æ•°è°ƒç”¨å¼€é”€
   - ä½¿ç”¨ `cuobjdump` éªŒè¯å†…è”è¡Œä¸ºï¼ˆæŸ¥æ‰¾ CAL æŒ‡ä»¤ï¼‰

3. **Launch Bounds ä¼˜åŒ–**ï¼š
   - `__launch_bounds__(MAX_THREADS, MIN_BLOCKS)` æç¤ºç¼–è¯‘å™¨ä¼˜åŒ–å¯„å­˜å™¨ä½¿ç”¨
   - å½±å“ Occupancy å’Œå¯„å­˜å™¨åˆ†é…ç­–ç•¥
   - é€šè¿‡ `-Xptxas=-v` æŸ¥çœ‹å¯„å­˜å™¨ä½¿ç”¨æƒ…å†µ

#### é¢„æœŸè¾“å‡º

```
==================================================================
   AI System Performance Lab - Kernel Structure Analyzer   
==================================================================
[Part 1] Testing Struct Alignment:
  DangerousStruct size (Host): 12 bytes
  DangerousStruct size (Device): 12 bytes
  SafeStruct size (Host): 16 bytes (aligned)
  SafeStruct size (Device): 16 bytes (aligned)

[Part 2] Testing Inline Behavior:
  Use 'cuobjdump -sass' to inspect CAL (Call) instructions
  __noinline__ functions should appear as CAL instructions

[Part 3] Testing Launch Bounds:
  Kernel without __launch_bounds__ uses: 32 registers
  Kernel with __launch_bounds__(256, 4) uses: 24 registers
  >> Register pressure reduced, Occupancy improved!
```

#### ABI åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `05_inspect_asm.sh` è„šæœ¬ï¼Œç”¨äºåˆ†æ SASS ä»£ç ä¸­çš„å†…è”è¡Œä¸ºï¼š

```bash
cd examples/01_cuda_basics
bash 05_inspect_asm.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰ã€‚

è¯¥è„šæœ¬ä¼šï¼š
- æœç´¢ SASS ä»£ç ä¸­çš„ `CAL`ï¼ˆCallï¼‰æŒ‡ä»¤
- éªŒè¯ `__noinline__` å‡½æ•°æ˜¯å¦çœŸçš„æ²¡æœ‰å†…è”
- åˆ†æå‡½æ•°è°ƒç”¨çš„å®é™…è¡Œä¸º

#### æ³¨æ„äº‹é¡¹

- ç»“æ„ä½“å¯¹é½é—®é¢˜åœ¨å®é™…é¡¹ç›®ä¸­å¯èƒ½å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„ Bug
- å‡½æ•°å†…è”ä¼šå½±å“è°ƒè¯•èƒ½åŠ›ï¼Œä½†å¯ä»¥æå‡æ€§èƒ½
- `__launch_bounds__` éœ€è¦æ ¹æ®å®é™… Occupancy éœ€æ±‚è°ƒæ•´å‚æ•°

---

### ç¬¬ 6 ç« ï¼šNVRTC è¿è¡Œæ—¶ç¼–è¯‘ä¸ Driver API (`06_nvrtc_jit.cpp`)

**è¿è¡Œæ—¶ç‰¹åŒ– + åŠ¨æ€åŠ è½½**ï¼šä½¿ç”¨ NVRTC åœ¨è¿è¡Œæ—¶ç”Ÿæˆ PTXï¼Œå¹¶é€šè¿‡ Driver API åŠ è½½æ‰§è¡Œã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **è¿è¡Œæ—¶ç‰¹åŒ–**ï¼šåœ¨ Host ç«¯å°†å¸¸é‡ï¼ˆå¦‚ `scale=5.0f`ï¼‰å†™å…¥ Kernel æºç å­—ç¬¦ä¸²ï¼Œè§¦å‘ç¼–è¯‘å™¨å¸¸é‡æŠ˜å ã€‚  
2. **æ¶æ„è‡ªé€‚åº”**ï¼šè¿è¡Œæ—¶è·å–å½“å‰ GPU çš„ Compute Capabilityï¼Œç”Ÿæˆå¯¹åº” `--gpu-architecture=compute_XY`ï¼Œé¿å…æ—§å¡ï¼ˆå¦‚ 1050, sm_61ï¼‰å‡ºç° `CUDA_ERROR_INVALID_PTX`ã€‚  
3. **æ··åˆ API**ï¼šNVRTCï¼ˆRuntime Compilationï¼‰+ Driver APIï¼ˆ`cuModuleLoadData` / `cuLaunchKernel`ï¼‰+ Runtime APIï¼ˆ`cudaMalloc` / `cudaMemcpy`ï¼‰æ··ç”¨ã€‚  
4. **æ—¥å¿—ä¸é”™è¯¯å¤„ç†**ï¼šæ‹‰å– NVRTC ç¼–è¯‘æ—¥å¿—ï¼ŒFail Fastã€‚  

#### è¿è¡Œ

```bash
# Linux
./bin/01_cuda_basics_06_nvrtc_jit

# Windows (PowerShell)
.\cmake-build-debug\bin\01_cuda_basics_06_nvrtc_jit.exe
```

#### é¢„æœŸè¾“å‡ºï¼ˆè€å¡ç¤ºä¾‹ï¼šGTX 1050, sm_61ï¼‰

```
[Host] Starting NVRTC JIT Compilation Demo...
[NVRTC] Specialized Source Code generated:
   out[i] = 5.0f * x[i] + y[i];
[NVRTC] PTX generated (... bytes).
[Host] Verification PASSED! Result is 7.0
```

---

### ç¬¬ 7 ç« ï¼šå†…å­˜æ¨¡å‹å…¨æ™¯ (`07_memory_spaces.cu`)

**å†…å­˜å±‚æ¬¡æ·±åº¦è§£æ**ï¼šæ¢ç´¢ CUDA çš„åœ°å€ç©ºé—´ã€UVA Zero-Copyã€Local Memory Spilling ä¸ `__restrict__` ä¼˜åŒ–ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **åœ°å€ç©ºé—´æ¢æµ‹**ï¼š
   - **Global Memory (HBM)**ï¼šè®¾å¤‡å…¨å±€å†…å­˜ï¼Œé€šè¿‡ `cudaMalloc` åˆ†é…
   - **Global Variable (Static)**ï¼šè®¾å¤‡é™æ€å˜é‡ï¼Œä½¿ç”¨ `__device__` å£°æ˜
   - **Shared Memory (SRAM)**ï¼šæ¯ä¸ª Block å…±äº«çš„ç‰‡ä¸Šé«˜é€Ÿç¼“å­˜
   - **Local Variable (Stack)**ï¼šçº¿ç¨‹å±€éƒ¨å˜é‡ï¼Œé€šå¸¸å­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­
   - **Host Pinned Memory (UVA)**ï¼šä¸»æœºå›ºå®šå†…å­˜ï¼Œå¯é€šè¿‡ UVA ç›´æ¥è®¿é—®

2. **UVA Zero-Copy å®æˆ˜**ï¼š
   - ä½¿ç”¨ `cudaHostAllocMapped` åˆ†é…ä¸»æœºå›ºå®šå†…å­˜
   - é€šè¿‡ Unified Virtual Addressing (UVA) å®ç° GPU ç›´æ¥è®¿é—® CPU å†…å­˜
   - éªŒè¯ Zero-Copy åŠŸèƒ½ï¼ˆæ— éœ€æ˜¾å¼ `cudaMemcpy`ï¼‰
   - **æ€§èƒ½è­¦å‘Š**ï¼šZero-Copy èµ° PCIe æ€»çº¿ï¼ˆ~64GB/sï¼‰ï¼Œè¿œæ…¢äº HBMï¼ˆ~2000GB/sï¼‰

3. **Local Memory Spillingï¼ˆå¯„å­˜å™¨æº¢å‡ºï¼‰**ï¼š
   - å½“å±€éƒ¨å˜é‡è¿‡å¤šæˆ–ä½¿ç”¨åŠ¨æ€ç´¢å¼•æ—¶ï¼Œç¼–è¯‘å™¨ä¼šå°†æ•°æ®æº¢å‡ºåˆ° Local Memory
   - Local Memory å®é™…å­˜å‚¨åœ¨ HBM ä¸­ï¼Œè®¿é—®å»¶è¿Ÿæé«˜ï¼ˆ~400 cyclesï¼‰
   - åœ¨ SASS ä»£ç ä¸­è¡¨ç°ä¸º `LDL`ï¼ˆLocal Loadï¼‰å’Œ `STL`ï¼ˆLocal Storeï¼‰æŒ‡ä»¤
   - ä¼šæ±¡æŸ“ L1 Cacheï¼Œä¸¥é‡å½±å“æ€§èƒ½

4. **`__restrict__` ä¼˜åŒ–**ï¼š
   - å‘ç¼–è¯‘å™¨ä¿è¯æŒ‡é’ˆä¸ä¼šé‡å ï¼ˆAliasingï¼‰
   - å…è®¸ç¼–è¯‘å™¨è¿›è¡Œæ›´æ¿€è¿›çš„ä¼˜åŒ–ï¼š
     - å‘é‡åŒ–åŠ è½½ï¼ˆ`LDG.128`ï¼‰
     - ä½¿ç”¨ Texture Cacheï¼ˆ`LDG.NC`ï¼‰
     - å‡å°‘å†…å­˜è®¿é—®æŒ‡ä»¤æ•°é‡
   - å¯¹æ¯”æ—  `__restrict__` å’Œæœ‰ `__restrict__` çš„ Kernelï¼Œè§‚å¯Ÿ SASS ä»£ç å·®å¼‚

#### é¢„æœŸè¾“å‡º

```
[Host] Starting Memory Hierarchy Analysis...
[Host] Launching Address Probe...

[Device] === Memory Address Map ===
  Global Memory (HBM) Ptr:    0x7f8a00000000
  Global Variable (Static):   0x7f8a00001000
  Shared Memory (SRAM):       0x7f8a00000000 (Small offset usually)
  Local Variable (Stack):     0x7f8a00000000 (If address taken -> Local Mem)
  Host Pinned Ptr (UVA/PCIe): 0x7f8a00002000
================================

[Device] Read from Host Pinned Memory: 999 (Success! UVA works)

[Host] To see Local Memory Spilling instructions (LDL/STL),
       please run the accompanying '07_inspect_sass.sh' script.
```

#### SASS åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `07_inspect_sass.sh` è„šæœ¬ï¼Œç”¨äºåˆ†æ SASS ä»£ç ä¸­çš„å†…å­˜è®¿é—®æ¨¡å¼ï¼š

```bash
cd examples/01_cuda_basics
bash 07_inspect_sass.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰ã€‚

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **æ£€æµ‹ Local Memory Spilling**ï¼šæœç´¢ `STL`/`LDL` æŒ‡ä»¤ï¼ŒéªŒè¯å¯„å­˜å™¨æº¢å‡º
- **å¯¹æ¯” `__restrict__` ä¼˜åŒ–**ï¼šåˆ—å‡ºç›¸å…³å‡½æ•°ï¼Œä¾¿äºæ‰‹åŠ¨å¯¹æ¯” SASS ä»£ç å·®å¼‚
- **éªŒè¯å†…å­˜è®¿é—®æ¨¡å¼**ï¼šè¯†åˆ«å‘é‡åŒ–åŠ è½½å’Œ Texture Cache ä½¿ç”¨

#### æ³¨æ„äº‹é¡¹

- UVA Zero-Copy é€‚åˆå°æ•°æ®é‡æˆ–éšæœºè®¿é—®æ¨¡å¼ï¼Œå¤§æ•°æ®é‡ä¼ è¾“åº”ä½¿ç”¨ `cudaMemcpy`
- Local Memory Spilling æ˜¯æ€§èƒ½æ€æ‰‹ï¼Œåº”å°½é‡é¿å…ï¼š
  - å‡å°‘å±€éƒ¨æ•°ç»„å¤§å°
  - ä½¿ç”¨ Shared Memory æ›¿ä»£å¤§å±€éƒ¨æ•°ç»„
  - é¿å…å¯¹å±€éƒ¨æ•°ç»„ä½¿ç”¨åŠ¨æ€ç´¢å¼•
- `__restrict__` æ˜¯æ€§èƒ½ä¼˜åŒ–çš„é‡è¦å·¥å…·ï¼Œä½†éœ€è¦ç¡®ä¿æŒ‡é’ˆç¡®å®ä¸é‡å 

---

### ç¬¬ 8 ç« ï¼šå¼‚æ­¥æ‰§è¡Œæ¨¡å‹ (`08_async_pipeline.cu`)

**Pipeline Concurrency**ï¼šå®ç° H2D -> Compute -> D2H ä¸‰çº§æµæ°´çº¿ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Pinned Memoryï¼ˆé¡µé”å®šå†…å­˜ï¼‰çš„å¿…è¦æ€§**ï¼š
   - ä½¿ç”¨ `cudaMallocHost` åˆ†é… Pinned Memoryï¼Œå…è®¸ DMA å¼•æ“ç›´æ¥è®¿é—®
   - Pageable Memoryï¼ˆæ™®é€š `malloc`ï¼‰ä¼šå¯¼è‡´é©±åŠ¨ä»‹å…¥è¿›è¡Œä¸´æ—¶æ‹·è´ï¼Œæ— æ³•å®ç°çœŸæ­£çš„å¼‚æ­¥ä¼ è¾“
   - Pinned Memory æ˜¯å¼‚æ­¥ä¼ è¾“çš„å‰ææ¡ä»¶

2. **å¤š Stream å¹¶å‘**ï¼š
   - åˆ›å»ºå¤šä¸ª CUDA Streamï¼ˆä½¿ç”¨ `cudaStreamCreateWithFlags` å’Œ `cudaStreamNonBlocking`ï¼‰
   - ä¸åŒ Stream ä¸­çš„æ“ä½œå¯ä»¥å¹¶å‘æ‰§è¡Œï¼Œæ©ç›– PCIe ä¼ è¾“å»¶è¿Ÿ
   - ç†æƒ³æƒ…å†µä¸‹ï¼Œå½“ Stream 0 åœ¨æ‰§è¡Œè®¡ç®—æ—¶ï¼ŒStream 1 å¯ä»¥åœ¨è¿›è¡Œæ•°æ®ä¼ è¾“

3. **Depth-First è°ƒåº¦ç­–ç•¥**ï¼š
   - æŒ‰ Chunk é¡ºåºå¾ªç¯åˆ†é… Streamï¼ˆ`stream_idx = i % n_streams`ï¼‰
   - æ¯ä¸ª Stream ä¾æ¬¡æ‰§è¡Œï¼šH2D Copy -> Compute -> D2H Copy
   - è¿™ç§æ¨¡å¼èƒ½æœ€å¤§åŒ– Overlapï¼šå½“ Stream 0 åœ¨è®¡ç®—æ—¶ï¼ŒStream 1 åœ¨æ‹·è´

4. **æµæ°´çº¿ Overlap éªŒè¯**ï¼š
   - å¯¹æ¯”ä¸²è¡Œæ¨¡å¼ï¼ˆPageable Memory + Default Streamï¼‰vs å¼‚æ­¥æµæ°´çº¿æ¨¡å¼ï¼ˆPinned Memory + Multi-Streamsï¼‰
   - ä½¿ç”¨ Nsight Systems å¯è§†åŒ–æ—¶é—´çº¿ï¼Œè§‚å¯Ÿ Copy å’Œ Compute çš„é‡å 
   - ç†æƒ³æƒ…å†µä¸‹ï¼Œå¼‚æ­¥æµæ°´çº¿èƒ½æ˜¾è‘—æå‡ååé‡

#### é¢„æœŸè¾“å‡º

```
GPU: NVIDIA GeForce RTX 4090
Data Size: 32.00 MB, Chunk Size: 1.00 MB

[Serial] Starting processing 32 chunks...
[Serial] Total Time: 245.67 ms
------------------------------------------------
[Pipeline] Starting processing 32 chunks with 4 streams...
[Pipeline] Total Time: 89.23 ms
```

#### æ€§èƒ½åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `08_profile_nsys.sh` è„šæœ¬ï¼Œä½¿ç”¨ Nsight Systems è¿›è¡Œæ€§èƒ½åˆ†æï¼š

```bash
cd examples/01_cuda_basics
bash 08_profile_nsys.sh
```

**æ³¨æ„**ï¼š
- è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰
- **ä»…æ”¯æŒ Linux/WSL ç¯å¢ƒ**ï¼ˆNsight Systems éœ€è¦ Linux ç¯å¢ƒï¼‰
- è„šæœ¬ä¼šç”Ÿæˆ `.nsys-rep` æ–‡ä»¶ï¼Œéœ€è¦åœ¨ Nsight Systems GUI ä¸­æ‰“å¼€

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **è¿½è¸ª CUDA API è°ƒç”¨**ï¼šè®°å½•æ‰€æœ‰ `cudaMemcpyAsync` å’Œ Kernel Launch
- **å¯è§†åŒ–æ—¶é—´çº¿**ï¼šåœ¨ Nsight Systems GUI ä¸­æŸ¥çœ‹ Copy å’Œ Compute çš„é‡å æƒ…å†µ
- **éªŒè¯ Overlap æ•ˆæœ**ï¼šè§‚å¯Ÿ "CUDA HW" è¡Œä¸­çš„å¹¶å‘æ‰§è¡Œæƒ…å†µ

#### æŠ€æœ¯ç»†èŠ‚

- **å¼‚æ­¥ä¼ è¾“**ï¼š`cudaMemcpyAsync` éœ€è¦ Pinned Memory æ‰èƒ½å®ç°çœŸæ­£çš„å¼‚æ­¥
- **Stream åŒæ­¥**ï¼šä½¿ç”¨ `cudaDeviceSynchronize()` ç­‰å¾…æ‰€æœ‰ Stream å®Œæˆ
- **è®¡ç®—è´Ÿè½½æ¨¡æ‹Ÿ**ï¼šä½¿ç”¨ `clock64()` è¿›è¡Œå¿™ç­‰å¾…ï¼Œæ¨¡æ‹Ÿé‡è®¡ç®—ä»»åŠ¡
- **Chunk å¤§å°è°ƒä¼˜**ï¼šåˆ‡å¾—å¤ªå°ä¼šå¯¼è‡´ Launch Overhead å æ¯”è¿‡é«˜ï¼Œåˆ‡å¾—å¤ªå¤§ Overlap æ•ˆæœå·®

#### æ³¨æ„äº‹é¡¹

- Pinned Memory åˆ†é…ä¼šå ç”¨ç³»ç»Ÿå†…å­˜ï¼Œä¸è¦è¿‡åº¦ä½¿ç”¨
- Stream æ•°é‡éœ€è¦æ ¹æ®ç¡¬ä»¶èƒ½åŠ›è°ƒæ•´ï¼ˆé€šå¸¸ 4-8 ä¸ª Stream æ•ˆæœè¾ƒå¥½ï¼‰
- ç†æƒ³çš„ Overlap æ˜¯ Compute Time â‰ˆ Copy Timeï¼Œéœ€è¦æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´ `KERNEL_LOAD` å‚æ•°
- Windows ç¯å¢ƒä¸‹æ— æ³•ç›´æ¥è¿è¡Œ `nsys`ï¼Œéœ€è¦åœ¨ WSL æˆ– Linux ç¯å¢ƒä¸­ä½¿ç”¨

---

### ç¬¬ 9 ç« ï¼šè°ƒè¯•ä¸é”™è¯¯è¯Šæ–­ (`09_debug_and_sanitizer.cu`)

**Bug Generator**ï¼šæ•…æ„åˆ¶é€ ä¸‰ç§å…¸å‹ GPU é”™è¯¯ï¼Œæ¼”ç¤º Compute Sanitizer çš„æ£€æµ‹èƒ½åŠ›ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Compute Sanitizer å·¥å…·å¥—ä»¶**ï¼š
   - **Memcheck**ï¼šæ£€æµ‹å†…å­˜è¶Šç•Œè®¿é—®ã€æœªåˆå§‹åŒ–å†…å­˜ä½¿ç”¨ã€å†…å­˜æ³„æ¼
   - **Racecheck**ï¼šæ£€æµ‹ Shared Memory å’Œ Global Memory çš„æ•°æ®ç«äº‰
   - **Synccheck**ï¼šæ£€æµ‹éæ³•åŒæ­¥æ“ä½œï¼ˆå¦‚åˆ†æ”¯å‘æ•£ä¸­çš„ `__syncthreads()`ï¼‰
   - è¿™äº›å·¥å…·æ˜¯ CUDA å®˜æ–¹æä¾›çš„è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹å·¥å…·ï¼Œç±»ä¼¼äº Valgrind

2. **å†…å­˜è¶Šç•Œæ£€æµ‹ï¼ˆOut-of-Boundsï¼‰**ï¼š
   - æ¼”ç¤ºå½“çº¿ç¨‹ç´¢å¼•è¶…å‡ºåˆ†é…çš„å†…å­˜èŒƒå›´æ—¶çš„è¡Œä¸º
   - `oob_kernel` ä¸­ï¼Œå½“ `idx == n` æ—¶å‘ç”Ÿè¶Šç•Œå†™å…¥
   - Memcheck èƒ½å¤Ÿç²¾ç¡®å®šä½è¶Šç•Œè®¿é—®çš„ä½ç½®å’Œçº¿ç¨‹ç´¢å¼•

3. **æ•°æ®ç«äº‰æ£€æµ‹ï¼ˆRace Conditionï¼‰**ï¼š
   - æ¼”ç¤ºå¤šä¸ªçº¿ç¨‹åŒæ—¶è¯»å†™ Shared Memory åŒä¸€åœ°å€çš„é—®é¢˜
   - `race_kernel` ä¸­ï¼Œæ‰€æœ‰çº¿ç¨‹åŒæ—¶æ‰§è¡Œ `s_val += 1`ï¼Œç»“æœæœªå®šä¹‰
   - Racecheck èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ç§ç«äº‰æ¡ä»¶ï¼Œå¹¶æŠ¥å‘Šå†²çªçš„çº¿ç¨‹

4. **éæ³•åŒæ­¥æ£€æµ‹ï¼ˆIllegal Synchronizationï¼‰**ï¼š
   - æ¼”ç¤ºåœ¨åˆ†æ”¯å‘æ•£åŒºåŸŸè°ƒç”¨ `__syncthreads()` çš„é—®é¢˜
   - `illegal_sync_kernel` ä¸­ï¼Œåªæœ‰ä¸€åŠçº¿ç¨‹èƒ½åˆ°è¾¾åŒæ­¥ç‚¹ï¼Œå¯¼è‡´æ­»é”
   - Synccheck èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ç§éæ³•åŒæ­¥ï¼Œå¹¶æŠ¥å‘Šå‘æ•£çš„åˆ†æ”¯

#### è¿è¡Œæ–¹å¼

```bash
# ç›´æ¥è¿è¡Œï¼ˆä¼šè§¦å‘é”™è¯¯ï¼Œä½†å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™ï¼‰
./bin/01_cuda_basics_09_debug_and_sanitizer 0  # Out-of-Bounds
./bin/01_cuda_basics_09_debug_and_sanitizer 1  # Race Condition
./bin/01_cuda_basics_09_debug_and_sanitizer 2  # Illegal Sync

# ä½¿ç”¨ Sanitizer æ£€æµ‹ï¼ˆæ¨èï¼‰
cd examples/01_cuda_basics
bash 09_run_sanitizer.sh
```

#### é¢„æœŸè¾“å‡ºï¼ˆä½¿ç”¨ Sanitizerï¼‰

```
==========================================================
   CASE 1: Detecting Out-of-Bounds Access (Memcheck)
==========================================================
========= COMPUTE-SANITIZER
========= Error: out of bounds access
=========     at 0x... in oob_kernel
=========     by thread (0,0,0) in block (0,0,0)
=========     Address 0x... is out of bounds
...

==========================================================
   CASE 2: Detecting Data Race (Racecheck)
==========================================================
========= COMPUTE-SANITIZER
========= Error: Race reported between Read access at ...
=========     at 0x... in race_kernel
=========     by thread (1,0,0) in block (0,0,0)
=========     and Write access at ...
=========     by thread (0,0,0) in block (0,0,0)
...

==========================================================
   CASE 3: Detecting Illegal Sync (Synccheck)
==========================================================
========= COMPUTE-SANITIZER
========= Error: Barrier divergence detected
=========     at 0x... in illegal_sync_kernel
=========     Barrier reached by 16 threads, expected 32
...
```

#### è°ƒè¯•å·¥å…·

é¡¹ç›®æä¾›äº† `09_run_sanitizer.sh` è„šæœ¬ï¼Œè‡ªåŠ¨è¿è¡Œä¸‰ç§ Sanitizer å·¥å…·ï¼š

```bash
cd examples/01_cuda_basics
bash 09_run_sanitizer.sh
```

**æ³¨æ„**ï¼š
- è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰
- **éœ€è¦å®‰è£… CUDA Toolkit**ï¼ˆCompute Sanitizer éš CUDA Toolkit ä¸€èµ·å®‰è£…ï¼‰
- è„šæœ¬ä¼šä¾æ¬¡è¿è¡Œä¸‰ç§æ£€æµ‹å·¥å…·ï¼Œè¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **è‡ªåŠ¨è¿è¡Œ Memcheck**ï¼šæ£€æµ‹å†…å­˜è¶Šç•Œå’Œæ³„æ¼
- **è‡ªåŠ¨è¿è¡Œ Racecheck**ï¼šæ£€æµ‹æ•°æ®ç«äº‰
- **è‡ªåŠ¨è¿è¡Œ Synccheck**ï¼šæ£€æµ‹éæ³•åŒæ­¥

#### æŠ€æœ¯ç»†èŠ‚

- **Compute Sanitizer**ï¼šCUDA 11.0+ æä¾›çš„è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹å·¥å…·
- **å†…å­˜è¶Šç•Œ**ï¼šå¯èƒ½å¯¼è‡´ç¨‹åºå´©æºƒæˆ–æ•°æ®æŸåï¼Œä½†æœ‰æ—¶å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™
- **æ•°æ®ç«äº‰**ï¼šç»“æœæœªå®šä¹‰ï¼Œå¯èƒ½å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„ Bug
- **éæ³•åŒæ­¥**ï¼šä¼šå¯¼è‡´æ­»é”æˆ–æœªå®šä¹‰è¡Œä¸ºï¼ŒSynccheck èƒ½å¤Ÿæ£€æµ‹åˆ°

#### æ³¨æ„äº‹é¡¹

- Compute Sanitizer ä¼šæ˜¾è‘—é™ä½ç¨‹åºæ€§èƒ½ï¼ˆé€šå¸¸æ…¢ 10-100 å€ï¼‰ï¼Œä»…ç”¨äºè°ƒè¯•
- æŸäº›é”™è¯¯ï¼ˆå¦‚å¼‚æ­¥é”™è¯¯ï¼‰å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™ï¼Œéœ€è¦ç­‰å¾…åŒæ­¥ç‚¹
- å»ºè®®åœ¨å¼€å‘é˜¶æ®µå®šæœŸä½¿ç”¨ Sanitizer æ£€æŸ¥ä»£ç 
- Windows ç¯å¢ƒä¸‹ Compute Sanitizer åŠŸèƒ½æœ‰é™ï¼Œå»ºè®®åœ¨ Linux/WSL ç¯å¢ƒä¸­ä½¿ç”¨

---

## ğŸ”§ å·¥å…·è„šæœ¬

- `01_fatbin_inspect.sh`ï¼šäºŒè¿›åˆ¶æ–‡ä»¶åˆ†æå·¥å…·ï¼Œç”¨äºæŸ¥çœ‹ PTX å’Œ SASS ä»£ç 
- `05_inspect_asm.sh`ï¼šSASS æ±‡ç¼–åˆ†æå·¥å…·ï¼Œç”¨äºéªŒè¯å‡½æ•°å†…è”è¡Œä¸º
- `07_inspect_sass.sh`ï¼šSASS å†…å­˜åˆ†æå·¥å…·ï¼Œç”¨äºæ£€æµ‹ Local Memory Spilling å’Œ `__restrict__` ä¼˜åŒ–æ•ˆæœ
- `08_profile_nsys.sh`ï¼šæ€§èƒ½åˆ†æè„šæœ¬ï¼ˆLinux/WSL ä¸“ç”¨ï¼‰ï¼Œä½¿ç”¨ Nsight Systems åˆ†æå¼‚æ­¥æµæ°´çº¿æ€§èƒ½
- `09_run_sanitizer.sh`ï¼šè°ƒè¯•å·¥å…·è„šæœ¬ï¼Œä½¿ç”¨ Compute Sanitizer æ£€æµ‹å†…å­˜è¶Šç•Œã€æ•°æ®ç«äº‰å’Œéæ³•åŒæ­¥

## ğŸ“ æ³¨æ„äº‹é¡¹

- æ‰€æœ‰ç¤ºä¾‹ä»£ç éµå¾ª CUDA 12+ è§„èŒƒ
- ä»£ç åŒ…å«å®Œæ•´çš„é”™è¯¯æ£€æŸ¥æœºåˆ¶
- æ”¯æŒ Windows å’Œ Linux å¹³å°
- å…¼å®¹ CUDA 12.0+ ç‰ˆæœ¬ï¼ˆéƒ¨åˆ†å­—æ®µåœ¨ CUDA 12+ ä¸­å·²ç§»é™¤ï¼Œä½¿ç”¨æ¡ä»¶ç¼–è¯‘å¤„ç†ï¼‰
