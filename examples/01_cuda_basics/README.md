# Module A: CUDA åŸºç¡€æ¶æ„

æœ¬ç›®å½•åŒ…å« CUDA æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ„ç›¸å…³çš„ç¤ºä¾‹ä»£ç ï¼Œæ˜¯ã€ŠAI ç³»ç»Ÿæ€§èƒ½å·¥ç¨‹ã€‹ä¸“æ  Module A çš„é…å¥—å®æˆ˜ä»£ç ã€‚

## ğŸ“š ç›®å½•

| ç« èŠ‚ | æ–‡ä»¶ | æ ¸å¿ƒå†…å®¹ | çŸ¥è¯†ç‚¹ |
|------|------|----------|--------|
| **ç¬¬ 1 ç« ** | `01_hello_modern.cu` | CUDA æ ¸å¿ƒæ¦‚å¿µæ€»è§ˆ | Grid-Block-Thread æ¨¡å‹ã€é”™è¯¯æ£€æŸ¥ã€å¼‚æ­¥æ‰§è¡Œã€Unified Memory |
| **ç¬¬ 2 ç« ** | `02_hardware_query.cu` | GPU ç¡¬ä»¶æ¶æ„æ·±åº¦è§£æ | SM æ¶æ„ã€å†…å­˜å±‚æ¬¡ã€L2 Cacheã€Tensor Core èƒ½åŠ›ã€å¸¦å®½åˆ†æ |
| **ç¬¬ 3 ç« ** | `03_grid_mapping.cu` | CUDA ç¼–ç¨‹æ¨¡å‹ç‰©ç†æ˜ å°„ | GigaThread Engine è°ƒåº¦ã€SM æ˜ å°„ã€Wavefront æ•ˆåº”ã€PTX å†…è”æ±‡ç¼– |
| **ç¬¬ 4 ç« ** | `04_warp_divergence.cu` | çº¿ç¨‹è°ƒåº¦ï¼šSIMT, Divergence ä¸ Replay | Warp å‘æ•£ã€Bank Conflictã€æŒ‡ä»¤é‡æ’­ã€æ€§èƒ½é‡åŒ– |
| **ç¬¬ 5 ç« ** | `05_kernel_structure.cu` | Kernel ç»“æ„ä¸ ABI åˆ†æ | ç»“æ„ä½“å¯¹é½é™·é˜±ã€å‡½æ•°å†…è”æ§åˆ¶ã€Launch Bounds ä¼˜åŒ– |
| **ç¬¬ 6 ç« ** | `06_nvrtc_jit.cpp` | NVRTC è¿è¡Œæ—¶ç¼–è¯‘ä¸ Driver API | è¿è¡Œæ—¶ç‰¹åŒ–ã€PTX åŠ¨æ€åŠ è½½ã€æ¶æ„è‡ªé€‚åº” |
| **ç¬¬ 7 ç« ** | `07_memory_spaces.cu` | å†…å­˜æ¨¡å‹å…¨æ™¯ | åœ°å€ç©ºé—´æ¢æµ‹ã€UVA Zero-Copyã€Local Memory Spillingã€__restrict__ ä¼˜åŒ– |
| **ç¬¬ 8 ç« ** | `08_async_pipeline.cu` | å¼‚æ­¥æ‰§è¡Œæ¨¡å‹ | Pinned Memoryã€å¤š Stream å¹¶å‘ã€Depth-First è°ƒåº¦ã€æµæ°´çº¿ Overlap |
| **ç¬¬ 9 ç« ** | `09_debug_and_sanitizer.cu` | è°ƒè¯•ä¸é”™è¯¯è¯Šæ–­ | Compute Sanitizerã€å†…å­˜è¶Šç•Œæ£€æµ‹ã€æ•°æ®ç«äº‰æ£€æµ‹ã€éæ³•åŒæ­¥æ£€æµ‹ |
| **ç¬¬ 10 ç« ** | `10_roofline_demo.cu` | æ€§èƒ½å»ºæ¨¡ç¬¬ä¸€æ€§åŸç† | Roofline æ¨¡å‹ã€å¸¦å®½æé™æµ‹è¯•ã€ç®—åŠ›æé™æµ‹è¯•ã€Arithmetic Intensity |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¼–è¯‘æ„å»º

#### Linux ç¯å¢ƒ
```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --parallel 8
```

#### Windows/CLion ç¯å¢ƒ
- ä½¿ç”¨ CLion ç›´æ¥æ„å»ºï¼ˆæ„å»ºè¾“å‡ºåœ¨ `cmake-build-debug` æˆ– `cmake-build-debug-visual-studio` ç›®å½•ï¼‰
- æˆ–æ‰‹åŠ¨æ„å»ºï¼š
```powershell
mkdir build
cd build
cmake .. -G "Visual Studio 17 2022" -A x64
cmake --build . --parallel 8
```

### è¿è¡Œç¤ºä¾‹

ç¼–è¯‘æˆåŠŸåï¼Œå¯æ‰§è¡Œæ–‡ä»¶ä½ç½®ï¼š
- **Linux**: `build/bin/` ç›®å½•
- **Windows/CLion**: `cmake-build-debug/bin/` æˆ– `cmake-build-debug-visual-studio/bin/` ç›®å½•

```bash
# Linux: åœ¨ build ç›®å½•ä¸‹è¿è¡Œ
./bin/01_cuda_basics_01_hello_modern
./bin/01_cuda_basics_02_hardware_query
./bin/01_cuda_basics_03_grid_mapping
./bin/01_cuda_basics_04_warp_divergence
./bin/01_cuda_basics_05_kernel_structure
./bin/01_cuda_basics_06_nvrtc_jit
./bin/01_cuda_basics_07_memory_spaces
./bin/01_cuda_basics_08_async_pipeline
./bin/01_cuda_basics_09_debug_and_sanitizer
./bin/01_cuda_basics_10_roofline_demo

# Windows/CLion: åœ¨ cmake-build-debug/bin ç›®å½•ä¸‹è¿è¡Œ
# æˆ–åœ¨ PowerShell ä¸­ï¼ˆä»é¡¹ç›®æ ¹ç›®å½•ï¼‰
.\cmake-build-debug\bin\01_cuda_basics_01_hello_modern.exe
.\cmake-build-debug\bin\01_cuda_basics_06_nvrtc_jit.exe
.\cmake-build-debug\bin\01_cuda_basics_07_memory_spaces.exe
.\cmake-build-debug\bin\01_cuda_basics_08_async_pipeline.exe
.\cmake-build-debug\bin\01_cuda_basics_09_debug_and_sanitizer.exe
.\cmake-build-debug\bin\01_cuda_basics_10_roofline_demo.exe
```

---

## ğŸ“– å„ç« è¯¦ç»†è¯´æ˜

### ç¬¬ 1 ç« ï¼šCUDA æ ¸å¿ƒæ¦‚å¿µæ€»è§ˆ (`01_hello_modern.cu`)

**ç°ä»£ç‰ˆ Hello World**ï¼šå±•ç¤º CUDA 12+ çš„å·¥ç¨‹è§„èŒƒå’Œç”Ÿäº§çº§ä»£ç ç‰¹å¾ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **å®å®šä¹‰å°è£…**ï¼šä½¿ç”¨ `CUDA_CHECK` å®åŒ…è£¹æ‰€æœ‰ CUDA API è°ƒç”¨ï¼Œç¡®ä¿åœ¨å‡ºé”™æ—¶èƒ½æ‰“å°å…·ä½“çš„æ–‡ä»¶åå’Œè¡Œå·ï¼Œå¹¶å®‰å…¨é€€å‡ºã€‚è¿™ç§ Fail Fast ç­–ç•¥åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è‡³å…³é‡è¦ã€‚

2. **ç¡¬ä»¶æ„ŸçŸ¥**ï¼šåœ¨ Kernel å†…éƒ¨é€šè¿‡ `__CUDA_ARCH__` å®åˆ¤æ–­å½“å‰ç¡¬ä»¶æ¶æ„ï¼ˆç¼–è¯‘æœŸå¸¸é‡ï¼‰ï¼ŒåŒæ—¶åœ¨ Host ç«¯ä½¿ç”¨ `cudaGetDeviceProperties` è¿›è¡Œè¿è¡Œæ—¶ç¡¬ä»¶æŸ¥è¯¢ã€‚

3. **å¼‚æ­¥æ‰§è¡Œä¸åŒæ­¥**ï¼šæ¼”ç¤º Kernel å¯åŠ¨çš„å¼‚æ­¥ç‰¹æ€§ï¼Œä»¥åŠ `cudaGetLastError()` å’Œ `cudaDeviceSynchronize()` çš„æ­£ç¡®ä½¿ç”¨ã€‚

4. **ç»Ÿä¸€å†…å­˜ç®¡ç†**ï¼šä½¿ç”¨ `cudaMallocManaged` ç®€åŒ–å†…å­˜åˆ†é…ï¼Œæ•°æ®ä¼šåœ¨ CPU/GPU é—´è‡ªåŠ¨æŒ‰éœ€è¿ç§»ï¼ˆPage Migrationï¼‰ã€‚

5. **çº¿ç¨‹ç´¢å¼•è®¡ç®—**ï¼šå±•ç¤º CUDA çš„ Grid-Block-Thread ä¸‰å±‚æ‰§è¡Œæ¨¡å‹ï¼Œé€šè¿‡ `global_id = blockIdx.x * blockDim.x + threadIdx.x` è®¡ç®—å…¨å±€çº¿ç¨‹ç´¢å¼•ã€‚

#### é¢„æœŸè¾“å‡º

```shell
[Host] Starting Modern CUDA Hello World...
[Host] GPU Name: NVIDIA GeForce RTX 5090
[Host] SM Count: 170
[Host] Compute Capability: 12.0
[Host] Launching Kernel...
[Device] Kernel running on SM arch sm_750
[Device] GridDim=1, BlockDim=32
[Host] Verifying results...
[Host] Verification PASSED! [OK]
```

#### äºŒè¿›åˆ¶åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `01_fatbin_inspect.sh` è„šæœ¬ï¼Œåˆ©ç”¨ `cuobjdump` å·¥å…·åˆ†æç¼–è¯‘åçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼š

```bash
cd examples/01_cuda_basics
bash 01_fatbin_inspect.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼š
- **Windows/CLion**: `cmake-build-debug/bin` æˆ– `cmake-build-debug-visual-studio/bin`
- **Linux**: `build/bin`

è¯¥è„šæœ¬å¯ä»¥å±•ç¤ºï¼š
- **PTXï¼ˆè™šæ‹Ÿæ¶æ„ï¼‰**ï¼šä¸­é—´è¡¨ç¤ºä»£ç ï¼Œç”±é©±åŠ¨ç¨‹åºåœ¨è¿è¡Œæ—¶ JIT ç¼–è¯‘åˆ°ç›®æ ‡æ¶æ„
- **SASSï¼ˆçœŸå®æ¶æ„ï¼‰**ï¼šå®é™…è¿è¡Œåœ¨ GPU ä¸Šçš„æœºå™¨ç 
```shell
=== 1. Inspecting Virtual Architectures (PTX) ===
PTX is just-in-time compiled by the driver.
arch = sm_75

=== 2. Inspecting Real Architectures (SASS) ===
SASS is the actual machine code running on silicon.
arch = sm_75
```
è¿™å¯ä»¥éªŒè¯ CMake é…ç½®ä¸­çš„ `CMAKE_CUDA_ARCHITECTURES` æ˜¯å¦ç”Ÿæ•ˆã€‚

---

### ç¬¬ 2 ç« ï¼šGPU ç¡¬ä»¶æ¶æ„æ·±åº¦è§£æ (`02_hardware_query.cu`)

**ç¡¬ä»¶æ‹“æ‰‘ä¾¦æ¢**ï¼šæŒ–æ˜ SM æ¶æ„ã€L2 Cacheã€Tensor Core èƒ½åŠ›ä¸å¸¦å®½æé™ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **è®¡ç®—èƒ½åŠ›ä¸æ¶æ„è¯†åˆ«**ï¼šæ ¹æ® Compute Capability è¯†åˆ« GPU æ¶æ„ï¼ˆHopperã€Ampereã€Volta ç­‰ï¼‰ï¼Œå¹¶æ¨ç®—æ¯ä¸ª SM çš„ CUDA Core æ•°é‡ã€‚

2. **SM å®è§‚æ‹“æ‰‘**ï¼šå±•ç¤ºå¤šå¤„ç†å™¨æ•°é‡ã€CUDA Core æ€»æ•°ç­‰å®è§‚è®¡ç®—èµ„æºã€‚

3. **å†…å­˜ä½“ç³»åˆ†æ**ï¼š
   - å…¨å±€å†…å­˜å®¹é‡ï¼ˆHBM/DDRï¼‰
   - å†…å­˜æ€»çº¿å®½åº¦
   - ç†è®ºå³°å€¼å¸¦å®½è®¡ç®—
   - **L2 Cache å¤§å°**ï¼ˆå…³é”®æ€§èƒ½æŒ‡æ ‡ï¼Œå½±å“æ•°æ®é©»ç•™æ§åˆ¶ï¼‰

4. **SM å¾®æ¶æ„èµ„æº**ï¼ˆOccupancy åˆ†æå…³é”®ï¼‰ï¼š
   - Shared Memory é™åˆ¶ï¼ˆæ¯ Block å’ŒåŠ¨æ€åˆ†é…ï¼‰
   - å¯„å­˜å™¨æ•°é‡é™åˆ¶
   - çº¿ç¨‹æ•°é™åˆ¶ï¼ˆæ¯ Block å’Œæ¯ SMï¼‰
   - Warp å¤§å°

5. **ç°ä»£ç‰¹æ€§æ”¯æŒä¾¦æµ‹**ï¼š
   - Unified Addressing (UVA)
   - Managed Memory (Page Migration)
   - TMA (Tensor Memory Accelerator) - Hopper æ¶æ„
   - Thread Block Clusters - Hopper æ¶æ„

#### é¢„æœŸè¾“å‡º

```shell
=================================================================
   AI System Performance Lab - Hardware Topology Detective
=================================================================
Detected 1 CUDA Capable Device(s)

[Device 0]: NVIDIA GeForce RTX 5090
-----------------------------------------------------------------
  [Architecture]
    Compute Capability      : 12.0 (Hopper / Blackwell class)
  [Compute Topology]
    Multiprocessors (SMs)   : 170
    CUDA Cores / SM         : Unknown (Architecture not indexed)
    GPU Clock Rate          : N/A (removed in CUDA 12+)
  [Memory Hierarchy]
    Global Memory (HBM/DDR) : 31.36 GB
    Memory Bus Width        : 512-bit
    Memory Clock Rate       : N/A (removed in CUDA 12+)
    Theoretical Bandwidth   : N/A (use nvml API for accurate value)
    L2 Cache Size           : 96.00 MB (Key for residency control)
  [SM Micro-Architecture]
    Max Shared Mem / Block  : 48.00 KB
    Max Shared Mem (Opt-in) : 99.00 KB (Dynamic)
    Max Registers / Block   : 65536
    Max Threads / Block     : 1024
    Max Threads / SM        : 1536
    Warp Size               : 32
  [Modern Features Support]
    Unified Addressing      : Yes
    Managed Memory          : Yes
    TMA (Tensor Mem Accel)  : Supported (Likely)
    Thread Block Clusters   : Supported (Likely)
```

#### æ³¨æ„äº‹é¡¹

- åœ¨ CUDA 12+ ç‰ˆæœ¬ä¸­ï¼Œ`clockRate` å’Œ `memoryClockRate` å­—æ®µå·²è¢«ç§»é™¤ï¼Œä»£ç ä½¿ç”¨æ¡ä»¶ç¼–è¯‘å…¼å®¹æ–°æ—§ç‰ˆæœ¬ã€‚
- å¦‚éœ€è·å–å‡†ç¡®çš„æ—¶é’Ÿé¢‘ç‡å’Œå¸¦å®½ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ NVML (NVIDIA Management Library) APIã€‚

---

### ç¬¬ 3 ç« ï¼šCUDA ç¼–ç¨‹æ¨¡å‹ç‰©ç†æ˜ å°„ (`03_grid_mapping.cu`)

**Grid Mapper**ï¼šå¯è§†åŒ– GigaThread Engine çš„è°ƒåº¦é€»è¾‘ä¸ç‰©ç† SM æ˜ å°„ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **PTX å†…è”æ±‡ç¼–**ï¼šä½¿ç”¨ `asm volatile("mov.u32 %0, %smid;")` ç›´æ¥è¯»å–ç¡¬ä»¶ç‰¹æ®Šå¯„å­˜å™¨ `%smid`ï¼Œè·å– Block å®é™…è¿è¡Œçš„ç‰©ç† SM IDã€‚è¿™æ˜¯æ¯” CUDA C++ API æ›´åº•å±‚çš„æ“ä½œï¼Œå…¼å®¹æ‰€æœ‰æ¶æ„ã€‚

2. **æ‰§è¡Œé¡ºåºè¿½è¸ª**ï¼šé€šè¿‡ Global Atomic æ“ä½œï¼ˆ`atomicAdd`ï¼‰è¿½è¸ª Block çš„çœŸå®æ‰§è¡Œé¡ºåºï¼ˆExecution Orderï¼‰ï¼ŒéªŒè¯ GigaThread Engine çš„è°ƒåº¦ç­–ç•¥ã€‚

3. **Wavefront æ•ˆåº”è§‚å¯Ÿ**ï¼š
   - é€šè¿‡æ¨¡æ‹Ÿè®¡ç®—è´Ÿè½½ï¼ˆBusy Waitï¼‰æ‹‰é•¿ Block æ‰§è¡Œæ—¶é—´
   - è§‚å¯Ÿå¤šæ³¢æ¬¡ï¼ˆWaveï¼‰è°ƒåº¦æ¨¡å¼
   - æ£€æµ‹å°¾éƒ¨æ•ˆåº”ï¼ˆTail Effectï¼‰ï¼šæœ€åä¸€ä¸ª Block å¯èƒ½ç‹¬å  GPU

4. **è´Ÿè½½å‡è¡¡åˆ†æ**ï¼š
   - ç»Ÿè®¡æ¯ä¸ª SM å¤„ç†çš„ Block æ•°é‡
   - éªŒè¯ Round-Robin åˆ†é…ç­–ç•¥
   - å¯è§†åŒ– Block ID åˆ° SM ID çš„æ˜ å°„å…³ç³»

#### é¢„æœŸè¾“å‡º

```shell
[Host] Starting Grid Scheduler Tracer...
[Host] GPU: NVIDIA GeForce RTX 5090, Total SMs: 170
[Host] Launching 3401 Blocks (approx 20 full waves + 1 tail)

[Analysis 1] SM Load Balance (Top 5 & Bottom 5):
  SM 00 processed 21 blocks
  SM 01 processed 20 blocks
  SM 02 processed 20 blocks
  SM 03 processed 20 blocks
  SM 04 processed 20 blocks
  ...

[Analysis 2] Tail Effect Detection:
  The very last block to run was logical Block 3350
  It ran on physical SM 162
  Note: While this block was running, other SMs might have been IDLE if the grid size wasn't aligned to waves.

[Visualizer] Logical Block ID -> Physical SM ID (First 64 Blocks):

  Blocks 000-015:   0   1  22  23  44  45  66  67  88  89 110 111 132 133   2   3
  Blocks 016-031:  24  25  46  47  68  69  90  91 112 113 134 135   4   5  26  27
  Blocks 032-047:  48  49  70  71  92  93 114 115 136 137   6   7  28  29  50  51
  Blocks 048-063:  72  73  94  95 116 117 138 139 154 155   8   9  30  31  52  53
```

#### æŠ€æœ¯ç»†èŠ‚

- **SM ID è¯»å–**ï¼šä½¿ç”¨ PTX æ±‡ç¼–ç›´æ¥è®¿é—®ç¡¬ä»¶å¯„å­˜å™¨ï¼Œæ¯”è½¯ä»¶ API æ›´åº•å±‚ã€æ›´å‡†ç¡®
- **åŸå­æ“ä½œ**ï¼š`atomicAdd` ä¿è¯æ‰§è¡Œé¡ºåºçš„å…¨å±€ä¸€è‡´æ€§ï¼Œç”¨äºè¿½è¸ªè°ƒåº¦é¡ºåº
- **æ—¶é’Ÿè®¡æ•°**ï¼šä½¿ç”¨ `clock64()` è®°å½• Block å¯åŠ¨æ—¶é—´æˆ³ï¼Œå¯ç”¨äºåˆ†æè°ƒåº¦å»¶è¿Ÿ

---

### ç¬¬ 4 ç« ï¼šçº¿ç¨‹è°ƒåº¦ï¼šSIMT, Divergence ä¸ Replay (`04_warp_divergence.cu`)

**Micro-benchmark**ï¼šé‡åŒ–åˆ†æ”¯å‘æ•£ä¸ Shared Memory Bank Conflict çš„ç‰©ç†ä»£ä»·ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Warp Divergenceï¼ˆåˆ†æ”¯å‘æ•£ï¼‰**ï¼š
   - **Baseline æ¨¡å¼**ï¼šæ‰€æœ‰çº¿ç¨‹æ‰§è¡Œç›¸åŒè·¯å¾„ï¼ŒSIMT å•å…ƒæ»¡è½½è¿è¡Œ
   - **Divergent æ¨¡å¼**ï¼šå¥‡å¶çº¿ç¨‹èµ°ä¸åŒåˆ†æ”¯ï¼Œç¡¬ä»¶ä¸²è¡ŒåŒ–æ‰§è¡Œï¼ˆå…ˆæ‰§è¡Œå¶æ•°çº¿ç¨‹ï¼Œå†æ‰§è¡Œå¥‡æ•°çº¿ç¨‹ï¼‰
   - **æ€§èƒ½å½±å“**ï¼šç†è®ºååé‡å‡åŠï¼ˆç†æƒ³æƒ…å†µ 2.0x æ€§èƒ½æŸå¤±ï¼‰

2. **Bank Conflictï¼ˆå­˜å‚¨ä½“å†²çªï¼‰**ï¼š
   - **æ— å†²çªè®¿é—®**ï¼šStride=1ï¼Œ32 ä¸ªçº¿ç¨‹è®¿é—®ä¸åŒ Bankï¼Œ1 ä¸ªå‘¨æœŸå®Œæˆ
   - **32-way å†²çª**ï¼šStride=32ï¼Œæ‰€æœ‰çº¿ç¨‹è®¿é—®åŒä¸€ Bankï¼ŒæŒ‡ä»¤é‡æ’­ 32 æ¬¡
   - **æ€§èƒ½å½±å“**ï¼šç†è®ºå»¶è¿Ÿå¢åŠ  32 å€ï¼ˆç†æƒ³æƒ…å†µ 32.0x æ€§èƒ½æŸå¤±ï¼‰

3. **æ€§èƒ½æµ‹é‡æŠ€æœ¯**ï¼š
   - ä½¿ç”¨ `clock64()` è¿›è¡Œé«˜ç²¾åº¦å‘¨æœŸè®¡æ•°
   - é€šè¿‡ `#pragma unroll` å‡å°‘å¾ªç¯å¼€é”€ï¼Œçªå‡ºè¢«æµ‹æ“ä½œ
   - ä½¿ç”¨ `volatile` é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–æ‰å†…å­˜è®¿é—®

4. **ç¼–è¯‘å™¨ä¼˜åŒ–é˜²æŠ¤**ï¼š
   - ä½¿ç”¨ `volatile` å˜é‡é˜²æ­¢ç¼–è¯‘å™¨ä¼˜åŒ–
   - é€šè¿‡æ­»ä»£ç è·¯å¾„ï¼ˆ`if (val == 999999.0f)`ï¼‰é˜²æ­¢æ­»ä»£ç æ¶ˆé™¤

#### é¢„æœŸè¾“å‡º

```shell
=================================================================
   AI System Performance Lab - SIMT & Replay Analyzer
=================================================================
Running on GPU: NVIDIA GeForce RTX 5090 (Arch sm_120)

[Experiment 1] Measuring Warp Divergence Cost (ALU)
  Baseline (No Branch) Cycles : 1
  Divergent (If-Else) Cycles  : 1
  >> Performance Penalty      : 1.00x Slower (Ideal: 2.0x)

[Experiment 2] Measuring Instruction Replay Cost (Shared Mem)
  Linear Access (No Conflict) : 39935 cycles
  Stride-32 (32-way Conflict) : 162122 cycles
  >> Replay Penalty           : 4.06x Slower (Ideal: 32.0x)

Note: 'Ideal' assumes pure isolation. Real hardware pipelines may hide some latency.
```

#### å®éªŒè®¾è®¡

- **å®éªŒ 1ï¼šMath Divergence**
  - å¯¹æ¯”æ— åˆ†æ”¯ä»£ç  vs å¥‡å¶åˆ†æ”¯ä»£ç 
  - éªŒè¯ ALU åˆ©ç”¨ç‡å‡åŠï¼ˆSIMT ä¸²è¡ŒåŒ–ï¼‰
  - ä½¿ç”¨æµ®ç‚¹è¿ç®—åˆ¶é€ è®¡ç®—è´Ÿè½½

- **å®éªŒ 2ï¼šBank Conflict Replay**
  - å¯¹æ¯”æ— å†²çªè®¿é—® vs 32-way Bank Conflict
  - éªŒè¯æŒ‡ä»¤é‡æ’­æœºåˆ¶
  - ä½¿ç”¨ Shared Memory è¯»åå†™æ“ä½œåˆ¶é€ ä¾èµ–é“¾

#### æ³¨æ„äº‹é¡¹

- å®é™…ç¡¬ä»¶æµæ°´çº¿å¯èƒ½ä¼šéšè—éƒ¨åˆ†å»¶è¿Ÿï¼Œå› æ­¤å®æµ‹å€¼å¯èƒ½ç•¥ä½äºç†æƒ³å€¼
- `clock64()` è¿”å›çš„æ˜¯ SM æ—¶é’Ÿå‘¨æœŸï¼Œä¸æ˜¯ç»å¯¹æ—¶é—´
- å¾ªç¯æ¬¡æ•°ï¼ˆ`PER_KERNEL_ITERS`ï¼‰éœ€è¦è¶³å¤Ÿå¤§ä»¥æ‘Šè–„æµ‹é‡å¼€é”€ï¼Œä½†ä¸è¦è§¦å‘ TDRï¼ˆè¶…æ—¶æ£€æµ‹ä¸æ¢å¤ï¼‰

---

---

### ç¬¬ 5 ç« ï¼šKernel ç»“æ„ä¸ ABI åˆ†æ (`05_kernel_structure.cu`)

**ABI æ·±åº¦è§£æ**ï¼šæ­ç¤º Host-Device è¾¹ç•Œä¸Šçš„é™·é˜±ä¸ä¼˜åŒ–æŠ€å·§ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **ç»“æ„ä½“å¯¹é½é™·é˜±**ï¼š
   - Host ç¼–è¯‘å™¨ï¼ˆGCC/MSVCï¼‰å’Œ Device ç¼–è¯‘å™¨ï¼ˆNVCCï¼‰å¯èƒ½é‡‡ç”¨ä¸åŒçš„ Padding ç­–ç•¥
   - `__align__` å…³é”®å­—å¼ºåˆ¶å¯¹é½ï¼Œé¿å…ç»“æ„ä½“å¸ƒå±€ä¸ä¸€è‡´å¯¼è‡´çš„ Bug
   - æ¼”ç¤ºä¸åŒå¯¹é½ç­–ç•¥å¯¹å†…å­˜å¸ƒå±€çš„å½±å“

2. **å‡½æ•°å†…è”æ§åˆ¶**ï¼š
   - `__noinline__`ï¼šå¼ºåˆ¶å‡½æ•°ä¸è¢«å†…è”ï¼Œç”¨äºè°ƒè¯•å’Œ ABI åˆ†æ
   - `__forceinline__`ï¼šå¼ºåˆ¶å†…è”ï¼Œæ¶ˆé™¤å‡½æ•°è°ƒç”¨å¼€é”€
   - ä½¿ç”¨ `cuobjdump` éªŒè¯å†…è”è¡Œä¸ºï¼ˆæŸ¥æ‰¾ CAL æŒ‡ä»¤ï¼‰

3. **Launch Bounds ä¼˜åŒ–**ï¼š
   - `__launch_bounds__(MAX_THREADS, MIN_BLOCKS)` æç¤ºç¼–è¯‘å™¨ä¼˜åŒ–å¯„å­˜å™¨ä½¿ç”¨
   - å½±å“ Occupancy å’Œå¯„å­˜å™¨åˆ†é…ç­–ç•¥
   - é€šè¿‡ `-Xptxas=-v` æŸ¥çœ‹å¯„å­˜å™¨ä½¿ç”¨æƒ…å†µ

#### é¢„æœŸè¾“å‡º

```shell
=== [Module A] 05. Kernel Structure & ABI Analysis ===

[Host] Checking Structure Layout...
[Host]   DangerousStruct: Offset of b = 4 bytes
[Host]   SafeStruct:      Offset of b = 4 bytes
[Host] Launching Alignment Kernel...
[Device] DangerousStruct: Offset of b = 4 bytes
[Device] SafeStruct:      Offset of b = 4 bytes
[Device] Values: s1.b=42 (Expected 42), s2.b=100 (Expected 100)

[Host] Inlining kernels executed. Run '05_inspect_asm.sh' to see SASS differences.

[Host] Launch Bounds kernels executed.
       CHECK YOUR COMPILE OUTPUT (Ninja log) for 'ptxas info' lines!
       You should see different register counts for default vs bounded kernels.
```

#### ABI åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `05_inspect_asm.sh` è„šæœ¬ï¼Œç”¨äºåˆ†æ SASS ä»£ç ä¸­çš„å†…è”è¡Œä¸ºï¼š

```bash
cd examples/01_cuda_basics
bash 05_inspect_asm.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰ã€‚

è¯¥è„šæœ¬ä¼šï¼š
- æœç´¢ SASS ä»£ç ä¸­çš„ `CAL`ï¼ˆCallï¼‰æŒ‡ä»¤
- éªŒè¯ `__noinline__` å‡½æ•°æ˜¯å¦çœŸçš„æ²¡æœ‰å†…è”
- åˆ†æå‡½æ•°è°ƒç”¨çš„å®é™…è¡Œä¸º
```shell
                                                                                      /* 0x000fcc0000000f00 */
        /*0050*/                   CALL.ABS.NOINC 0x0 ;                               /* 0x0000000000007943 */
                                                                                      /* 0x000fea0003c00000 */
        /*0060*/                   MOV R3, 0x4 ;                                      /* 0x0000000400037802 */
--
        /*0120*/                   MOV R21, 0x0 ;                                     /* 0x0000000000157802 */
                                                                                      /* 0x000fcc0000000f00 */
        /*0130*/                   CALL.ABS.NOINC 0x0 ;                               /* 0x0000000000007943 */
                                                                                      /* 0x001fea0003c00000 */
        /*0140*/                   IMAD.MOV.U32 R8, RZ, RZ, 0x4 ;                     /* 0x00000004ff087424 */
--
        /*01e0*/                   MOV R21, 0x0 ;                                     /* 0x0000000000157802 */
                                                                                      /* 0x000fcc0000000f00 */
        /*01f0*/                   CALL.ABS.NOINC 0x0 ;                               /* 0x0000000000007943 */
                                                                                      /* 0x001fea0003c00000 */
        /*0200*/                   IMAD.MOV.U32 R8, RZ, RZ, c[0x0][0x164] ;           /* 0x00005900ff087624 */
--
        /*02a0*/                   MOV R21, 0x0 ;                                     /* 0x0000000000157802 */
                                                                                      /* 0x000fcc0000000f00 */
        /*02b0*/                   CALL.ABS.NOINC 0x0 ;                               /* 0x0000000000007943 */
                                                                                      /* 0x001fea0003c00000 */
        /*02c0*/                   EXIT ;                                             /* 0x000000000000794d */

--------------------------------------------------------
NOTE:
1. 'CAL' instruction means a subroutine call (no-inline).
2. If you don't see CAL for forceinline_kernel, it was successfully inlined.
========================================================

========================================================
   SASS Analysis: Parameter Loading (Constant Memory)
========================================================
Searching for Constant Memory loads (c[0x0])...
These instructions move kernel arguments from Bank 0 to Registers:

        /*0000*/                   MOV R1, c[0x0][0x28] ;                             /* 0x00000a0000017a02 */
        /*0040*/                   ISETP.GE.AND P0, PT, R0, c[0x0][0x168], PT ;       /* 0x00005a0000007a0c */
        /*ef80*/                   IMAD.WIDE R2, R0, R3, c[0x0][0x160] ;              /* 0x0000580000027625 */
        /*0000*/                   MOV R1, c[0x0][0x28] ;                             /* 0x00000a0000017a02 */
        /*0040*/                   ISETP.GE.AND P0, PT, R0, c[0x0][0x168], PT ;       /* 0x00005a0000007a0c */
        /*ef80*/                   IMAD.WIDE R2, R0, R3, c[0x0][0x160] ;              /* 0x0000580000027625 */
        /*0000*/                   MOV R1, c[0x0][0x28] ;                             /* 0x00000a0000017a02 */
        /*0030*/                   IADD3 R0, R2, c[0x0][0x168], RZ ;                  /* 0x00005a0002007a10 */
        /*0040*/                   IMAD.WIDE R2, R2, R3, c[0x0][0x160] ;              /* 0x0000580002027625 */
        /*0000*/                   MOV R1, c[0x0][0x28] ;                             /* 0x00000a0000017a02 */

... (showing first 10 occurrences)
========================================================
```
#### æ³¨æ„äº‹é¡¹

- ç»“æ„ä½“å¯¹é½é—®é¢˜åœ¨å®é™…é¡¹ç›®ä¸­å¯èƒ½å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„ Bug
- å‡½æ•°å†…è”ä¼šå½±å“è°ƒè¯•èƒ½åŠ›ï¼Œä½†å¯ä»¥æå‡æ€§èƒ½
- `__launch_bounds__` éœ€è¦æ ¹æ®å®é™… Occupancy éœ€æ±‚è°ƒæ•´å‚æ•°

---

### ç¬¬ 6 ç« ï¼šNVRTC è¿è¡Œæ—¶ç¼–è¯‘ä¸ Driver API (`06_nvrtc_jit.cpp`)

**è¿è¡Œæ—¶ç‰¹åŒ– + åŠ¨æ€åŠ è½½**ï¼šä½¿ç”¨ NVRTC åœ¨è¿è¡Œæ—¶ç”Ÿæˆ PTXï¼Œå¹¶é€šè¿‡ Driver API åŠ è½½æ‰§è¡Œã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **è¿è¡Œæ—¶ç‰¹åŒ–**ï¼šåœ¨ Host ç«¯å°†å¸¸é‡ï¼ˆå¦‚ `scale=5.0f`ï¼‰å†™å…¥ Kernel æºç å­—ç¬¦ä¸²ï¼Œè§¦å‘ç¼–è¯‘å™¨å¸¸é‡æŠ˜å ã€‚  
2. **æ¶æ„è‡ªé€‚åº”**ï¼šè¿è¡Œæ—¶è·å–å½“å‰ GPU çš„ Compute Capabilityï¼Œç”Ÿæˆå¯¹åº” `--gpu-architecture=compute_XY`ï¼Œé¿å…æ—§å¡ï¼ˆå¦‚ 1050, sm_61ï¼‰å‡ºç° `CUDA_ERROR_INVALID_PTX`ã€‚  
3. **æ··åˆ API**ï¼šNVRTCï¼ˆRuntime Compilationï¼‰+ Driver APIï¼ˆ`cuModuleLoadData` / `cuLaunchKernel`ï¼‰+ Runtime APIï¼ˆ`cudaMalloc` / `cudaMemcpy`ï¼‰æ··ç”¨ã€‚  
4. **æ—¥å¿—ä¸é”™è¯¯å¤„ç†**ï¼šæ‹‰å– NVRTC ç¼–è¯‘æ—¥å¿—ï¼ŒFail Fastã€‚  

#### è¿è¡Œ

```bash
# Linux
./bin/01_cuda_basics_06_nvrtc_jit

# Windows (PowerShell)
.\cmake-build-debug\bin\01_cuda_basics_06_nvrtc_jit.exe
```

#### é¢„æœŸè¾“å‡ºï¼ˆè€å¡ç¤ºä¾‹ï¼šGTX 1050, sm_61ï¼‰

```shell
[Host] Starting NVRTC JIT Compilation Demo...
[NVRTC] Specialized Source Code generated:
   out[i] = 5.0f * x[i] + y[i];
[NVRTC] PTX generated (1272 bytes).
[Host] Verification PASSED! Result is 7.0
```

---

### ç¬¬ 7 ç« ï¼šå†…å­˜æ¨¡å‹å…¨æ™¯ (`07_memory_spaces.cu`)

**å†…å­˜å±‚æ¬¡æ·±åº¦è§£æ**ï¼šæ¢ç´¢ CUDA çš„åœ°å€ç©ºé—´ã€UVA Zero-Copyã€Local Memory Spilling ä¸ `__restrict__` ä¼˜åŒ–ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **åœ°å€ç©ºé—´æ¢æµ‹**ï¼š
   - **Global Memory (HBM)**ï¼šè®¾å¤‡å…¨å±€å†…å­˜ï¼Œé€šè¿‡ `cudaMalloc` åˆ†é…
   - **Global Variable (Static)**ï¼šè®¾å¤‡é™æ€å˜é‡ï¼Œä½¿ç”¨ `__device__` å£°æ˜
   - **Shared Memory (SRAM)**ï¼šæ¯ä¸ª Block å…±äº«çš„ç‰‡ä¸Šé«˜é€Ÿç¼“å­˜
   - **Local Variable (Stack)**ï¼šçº¿ç¨‹å±€éƒ¨å˜é‡ï¼Œé€šå¸¸å­˜å‚¨åœ¨å¯„å­˜å™¨ä¸­
   - **Host Pinned Memory (UVA)**ï¼šä¸»æœºå›ºå®šå†…å­˜ï¼Œå¯é€šè¿‡ UVA ç›´æ¥è®¿é—®

2. **UVA Zero-Copy å®æˆ˜**ï¼š
   - ä½¿ç”¨ `cudaHostAllocMapped` åˆ†é…ä¸»æœºå›ºå®šå†…å­˜
   - é€šè¿‡ Unified Virtual Addressing (UVA) å®ç° GPU ç›´æ¥è®¿é—® CPU å†…å­˜
   - éªŒè¯ Zero-Copy åŠŸèƒ½ï¼ˆæ— éœ€æ˜¾å¼ `cudaMemcpy`ï¼‰
   - **æ€§èƒ½è­¦å‘Š**ï¼šZero-Copy èµ° PCIe æ€»çº¿ï¼ˆ~64GB/sï¼‰ï¼Œè¿œæ…¢äº HBMï¼ˆ~2000GB/sï¼‰

3. **Local Memory Spillingï¼ˆå¯„å­˜å™¨æº¢å‡ºï¼‰**ï¼š
   - å½“å±€éƒ¨å˜é‡è¿‡å¤šæˆ–ä½¿ç”¨åŠ¨æ€ç´¢å¼•æ—¶ï¼Œç¼–è¯‘å™¨ä¼šå°†æ•°æ®æº¢å‡ºåˆ° Local Memory
   - Local Memory å®é™…å­˜å‚¨åœ¨ HBM ä¸­ï¼Œè®¿é—®å»¶è¿Ÿæé«˜ï¼ˆ~400 cyclesï¼‰
   - åœ¨ SASS ä»£ç ä¸­è¡¨ç°ä¸º `LDL`ï¼ˆLocal Loadï¼‰å’Œ `STL`ï¼ˆLocal Storeï¼‰æŒ‡ä»¤
   - ä¼šæ±¡æŸ“ L1 Cacheï¼Œä¸¥é‡å½±å“æ€§èƒ½

4. **`__restrict__` ä¼˜åŒ–**ï¼š
   - å‘ç¼–è¯‘å™¨ä¿è¯æŒ‡é’ˆä¸ä¼šé‡å ï¼ˆAliasingï¼‰
   - å…è®¸ç¼–è¯‘å™¨è¿›è¡Œæ›´æ¿€è¿›çš„ä¼˜åŒ–ï¼š
     - å‘é‡åŒ–åŠ è½½ï¼ˆ`LDG.128`ï¼‰
     - ä½¿ç”¨ Texture Cacheï¼ˆ`LDG.NC`ï¼‰
     - å‡å°‘å†…å­˜è®¿é—®æŒ‡ä»¤æ•°é‡
   - å¯¹æ¯”æ—  `__restrict__` å’Œæœ‰ `__restrict__` çš„ Kernelï¼Œè§‚å¯Ÿ SASS ä»£ç å·®å¼‚

#### é¢„æœŸè¾“å‡º

```shell
[Host] Starting Memory Hierarchy Analysis...
[Host] Launching Address Probe...

[Device] === Memory Address Map ===
  Global Memory (HBM) Ptr:    0x78138b000000
  Global Variable (Static):   0x78138b400800
  Shared Memory (SRAM):       0x781400000400 (Small offset usually)
  Local Variable (Stack):     0x78139dfffce0 (If address taken -> Local Mem)
  Host Pinned Ptr (UVA/PCIe): 0x78138b200000
================================

[Device] Read from Host Pinned Memory: 999 (Success! UVA works)

[Host] To see Local Memory Spilling instructions (LDL/STL),
       please run the accompanying '07_inspect_sass.sh' script.
```

#### SASS åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `07_inspect_sass.sh` è„šæœ¬ï¼Œç”¨äºåˆ†æ SASS ä»£ç ä¸­çš„å†…å­˜è®¿é—®æ¨¡å¼ï¼š

```bash
cd examples/01_cuda_basics
bash 07_inspect_sass.sh
```

**æ³¨æ„**ï¼šè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰ã€‚

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **æ£€æµ‹ Local Memory Spilling**ï¼šæœç´¢ `STL`/`LDL` æŒ‡ä»¤ï¼ŒéªŒè¯å¯„å­˜å™¨æº¢å‡º
- **å¯¹æ¯” `__restrict__` ä¼˜åŒ–**ï¼šåˆ—å‡ºç›¸å…³å‡½æ•°ï¼Œä¾¿äºæ‰‹åŠ¨å¯¹æ¯” SASS ä»£ç å·®å¼‚
- **éªŒè¯å†…å­˜è®¿é—®æ¨¡å¼**ï¼šè¯†åˆ«å‘é‡åŒ–åŠ è½½å’Œ Texture Cache ä½¿ç”¨
```shell
========================================================
   SASS Analysis: Local Memory Spilling
========================================================
Searching for Local Store (STL) and Local Load (LDL) instructions...
These indicate data is spilling to HBM (Slow!).

                                                                                      /* 0x000fc40000000028 */
        /*00c0*/                   FFMA R9, R3.reuse, R40.reuse, 5 ;                  /* 0x40a0000003097423 */
                                                                                      /* 0x0c0fe40000000028 */
        /*00d0*/                   FFMA R8, R3.reuse, R40.reuse, 4 ;                  /* 0x4080000003087423 */
                                                                                      /* 0x0c0fe20000000028 */
        /*00e0*/                   STL.128 [R1], R4 ;                                 /* 0x0000000401007387 */
--
                                                                                      /* 0x0c0fe40000000028 */
        /*0110*/                   FFMA R13, R3.reuse, R40.reuse, 9 ;                 /* 0x41100000030d7423 */
                                                                                      /* 0x0c0fe40000000028 */
        /*0120*/                   FFMA R12, R3.reuse, R40.reuse, 8 ;                 /* 0x41000000030c7423 */
                                                                                      /* 0x0c0fe20000000028 */
        /*0130*/                   STL.128 [R1+0x10], R8 ;                            /* 0x0000100801007387 */
--
                                                                                      /* 0x0c0fe40000000028 */
        /*0160*/                   FFMA R29, R3.reuse, R40.reuse, 37 ;                /* 0x42140000031d7423 */
                                                                                      /* 0x0c0fe40000000028 */
        /*0170*/                   FFMA R28, R3.reuse, R40.reuse, 36 ;                /* 0x42100000031c7423 */
                                                                                      /* 0x0c0fe20000000028 */
        /*0180*/                   STL.128 [R1+0x20], R12 ;                           /* 0x0000200c01007387 */

NOTE: If you see STL/LDL inside 'force_local_memory_spill', spilling occurred.
========================================================

========================================================
   SASS Analysis: __restrict__ Optimization
========================================================
Comparing No-Restrict vs With-Restrict kernels...
Ideally, 'With-Restrict' might use LDG.NC (Non-coherent/Texture) or fewer instructions.

[Functions found in binary]
                Function : _Z17add_with_restrictPfS_S_i
                Function : _Z15add_no_restrictPfS_S_i

Tip: Use 'cuobjdump -sass ... > out.txt' to manually compare the assembly.
========================================================
```
#### æ³¨æ„äº‹é¡¹

- UVA Zero-Copy é€‚åˆå°æ•°æ®é‡æˆ–éšæœºè®¿é—®æ¨¡å¼ï¼Œå¤§æ•°æ®é‡ä¼ è¾“åº”ä½¿ç”¨ `cudaMemcpy`
- Local Memory Spilling æ˜¯æ€§èƒ½æ€æ‰‹ï¼Œåº”å°½é‡é¿å…ï¼š
  - å‡å°‘å±€éƒ¨æ•°ç»„å¤§å°
  - ä½¿ç”¨ Shared Memory æ›¿ä»£å¤§å±€éƒ¨æ•°ç»„
  - é¿å…å¯¹å±€éƒ¨æ•°ç»„ä½¿ç”¨åŠ¨æ€ç´¢å¼•
- `__restrict__` æ˜¯æ€§èƒ½ä¼˜åŒ–çš„é‡è¦å·¥å…·ï¼Œä½†éœ€è¦ç¡®ä¿æŒ‡é’ˆç¡®å®ä¸é‡å 

---

### ç¬¬ 8 ç« ï¼šå¼‚æ­¥æ‰§è¡Œæ¨¡å‹ (`08_async_pipeline.cu`)

**Pipeline Concurrency**ï¼šå®ç° H2D -> Compute -> D2H ä¸‰çº§æµæ°´çº¿ï¼Œæœ€å¤§åŒ– GPU åˆ©ç”¨ç‡ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Pinned Memoryï¼ˆé¡µé”å®šå†…å­˜ï¼‰çš„å¿…è¦æ€§**ï¼š
   - ä½¿ç”¨ `cudaMallocHost` åˆ†é… Pinned Memoryï¼Œå…è®¸ DMA å¼•æ“ç›´æ¥è®¿é—®
   - Pageable Memoryï¼ˆæ™®é€š `malloc`ï¼‰ä¼šå¯¼è‡´é©±åŠ¨ä»‹å…¥è¿›è¡Œä¸´æ—¶æ‹·è´ï¼Œæ— æ³•å®ç°çœŸæ­£çš„å¼‚æ­¥ä¼ è¾“
   - Pinned Memory æ˜¯å¼‚æ­¥ä¼ è¾“çš„å‰ææ¡ä»¶

2. **å¤š Stream å¹¶å‘**ï¼š
   - åˆ›å»ºå¤šä¸ª CUDA Streamï¼ˆä½¿ç”¨ `cudaStreamCreateWithFlags` å’Œ `cudaStreamNonBlocking`ï¼‰
   - ä¸åŒ Stream ä¸­çš„æ“ä½œå¯ä»¥å¹¶å‘æ‰§è¡Œï¼Œæ©ç›– PCIe ä¼ è¾“å»¶è¿Ÿ
   - ç†æƒ³æƒ…å†µä¸‹ï¼Œå½“ Stream 0 åœ¨æ‰§è¡Œè®¡ç®—æ—¶ï¼ŒStream 1 å¯ä»¥åœ¨è¿›è¡Œæ•°æ®ä¼ è¾“

3. **Depth-First è°ƒåº¦ç­–ç•¥**ï¼š
   - æŒ‰ Chunk é¡ºåºå¾ªç¯åˆ†é… Streamï¼ˆ`stream_idx = i % n_streams`ï¼‰
   - æ¯ä¸ª Stream ä¾æ¬¡æ‰§è¡Œï¼šH2D Copy -> Compute -> D2H Copy
   - è¿™ç§æ¨¡å¼èƒ½æœ€å¤§åŒ– Overlapï¼šå½“ Stream 0 åœ¨è®¡ç®—æ—¶ï¼ŒStream 1 åœ¨æ‹·è´

4. **æµæ°´çº¿ Overlap éªŒè¯**ï¼š
   - å¯¹æ¯”ä¸²è¡Œæ¨¡å¼ï¼ˆPageable Memory + Default Streamï¼‰vs å¼‚æ­¥æµæ°´çº¿æ¨¡å¼ï¼ˆPinned Memory + Multi-Streamsï¼‰
   - ä½¿ç”¨ Nsight Systems å¯è§†åŒ–æ—¶é—´çº¿ï¼Œè§‚å¯Ÿ Copy å’Œ Compute çš„é‡å 
   - ç†æƒ³æƒ…å†µä¸‹ï¼Œå¼‚æ­¥æµæ°´çº¿èƒ½æ˜¾è‘—æå‡ååé‡

#### é¢„æœŸè¾“å‡º

```
GPU: NVIDIA GeForce RTX 5090
Data Size: 32.00 MB, Chunk Size: 1.00 MB

[Serial] Starting processing 32 chunks...
[Serial] Total Time: 40.20 ms
------------------------------------------------
[Pipeline] Starting processing 32 chunks with 4 streams...
[Pipeline] Total Time: 1.32 ms
```

#### æ€§èƒ½åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `08_profile_nsys.sh` è„šæœ¬ï¼Œä½¿ç”¨ Nsight Systems è¿›è¡Œæ€§èƒ½åˆ†æï¼š

```bash
cd examples/01_cuda_basics
bash 08_profile_nsys.sh
```

**æ³¨æ„**ï¼š
- è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰
- **ä»…æ”¯æŒ Linux/WSL ç¯å¢ƒ**ï¼ˆNsight Systems éœ€è¦ Linux ç¯å¢ƒï¼‰
- è„šæœ¬ä¼šç”Ÿæˆ `.nsys-rep` æ–‡ä»¶ï¼Œéœ€è¦åœ¨ Nsight Systems GUI ä¸­æ‰“å¼€

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **è¿½è¸ª CUDA API è°ƒç”¨**ï¼šè®°å½•æ‰€æœ‰ `cudaMemcpyAsync` å’Œ Kernel Launch
- **å¯è§†åŒ–æ—¶é—´çº¿**ï¼šåœ¨ Nsight Systems GUI ä¸­æŸ¥çœ‹ Copy å’Œ Compute çš„é‡å æƒ…å†µ
- **éªŒè¯ Overlap æ•ˆæœ**ï¼šè§‚å¯Ÿ "CUDA HW" è¡Œä¸­çš„å¹¶å‘æ‰§è¡Œæƒ…å†µ
```shell
========================================================
   Profiling with Nsight Systems (nsys)
========================================================
Tracing CUDA API and GPU Workload...

Collecting data...
GPU: NVIDIA GeForce RTX 5090
Data Size: 32.00 MB, Chunk Size: 1.00 MB

[Serial] Starting processing 32 chunks...
[Serial] Total Time: 14.20 ms
------------------------------------------------
[Pipeline] Starting processing 32 chunks with 4 streams...
[Pipeline] Total Time: 1.41 ms
Generating '/tmp/nsys-report-c086.qdstrm'
[1/1] [========================100%] pipeline_trace.nsys-rep
Generated:
        /data/AI-System-Performance-Lab/build/pipeline_trace.nsys-rep

========================================================
Done! Please open 'pipeline_trace.nsys-rep' in Nsight Systems GUI.
Look for the 'CUDA HW' row to see the overlap.
========================================================
```
#### æŠ€æœ¯ç»†èŠ‚

- **å¼‚æ­¥ä¼ è¾“**ï¼š`cudaMemcpyAsync` éœ€è¦ Pinned Memory æ‰èƒ½å®ç°çœŸæ­£çš„å¼‚æ­¥
- **Stream åŒæ­¥**ï¼šä½¿ç”¨ `cudaDeviceSynchronize()` ç­‰å¾…æ‰€æœ‰ Stream å®Œæˆ
- **è®¡ç®—è´Ÿè½½æ¨¡æ‹Ÿ**ï¼šä½¿ç”¨ `clock64()` è¿›è¡Œå¿™ç­‰å¾…ï¼Œæ¨¡æ‹Ÿé‡è®¡ç®—ä»»åŠ¡
- **Chunk å¤§å°è°ƒä¼˜**ï¼šåˆ‡å¾—å¤ªå°ä¼šå¯¼è‡´ Launch Overhead å æ¯”è¿‡é«˜ï¼Œåˆ‡å¾—å¤ªå¤§ Overlap æ•ˆæœå·®

#### æ³¨æ„äº‹é¡¹

- Pinned Memory åˆ†é…ä¼šå ç”¨ç³»ç»Ÿå†…å­˜ï¼Œä¸è¦è¿‡åº¦ä½¿ç”¨
- Stream æ•°é‡éœ€è¦æ ¹æ®ç¡¬ä»¶èƒ½åŠ›è°ƒæ•´ï¼ˆé€šå¸¸ 4-8 ä¸ª Stream æ•ˆæœè¾ƒå¥½ï¼‰
- ç†æƒ³çš„ Overlap æ˜¯ Compute Time â‰ˆ Copy Timeï¼Œéœ€è¦æ ¹æ®å®é™…è´Ÿè½½è°ƒæ•´ `KERNEL_LOAD` å‚æ•°
- Windows ç¯å¢ƒä¸‹æ— æ³•ç›´æ¥è¿è¡Œ `nsys`ï¼Œéœ€è¦åœ¨ WSL æˆ– Linux ç¯å¢ƒä¸­ä½¿ç”¨

---

### ç¬¬ 9 ç« ï¼šè°ƒè¯•ä¸é”™è¯¯è¯Šæ–­ (`09_debug_and_sanitizer.cu`)

**Bug Generator**ï¼šæ•…æ„åˆ¶é€ ä¸‰ç§å…¸å‹ GPU é”™è¯¯ï¼Œæ¼”ç¤º Compute Sanitizer çš„æ£€æµ‹èƒ½åŠ›ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Compute Sanitizer å·¥å…·å¥—ä»¶**ï¼š
   - **Memcheck**ï¼šæ£€æµ‹å†…å­˜è¶Šç•Œè®¿é—®ã€æœªåˆå§‹åŒ–å†…å­˜ä½¿ç”¨ã€å†…å­˜æ³„æ¼
   - **Racecheck**ï¼šæ£€æµ‹ Shared Memory å’Œ Global Memory çš„æ•°æ®ç«äº‰
   - **Synccheck**ï¼šæ£€æµ‹éæ³•åŒæ­¥æ“ä½œï¼ˆå¦‚åˆ†æ”¯å‘æ•£ä¸­çš„ `__syncthreads()`ï¼‰
   - è¿™äº›å·¥å…·æ˜¯ CUDA å®˜æ–¹æä¾›çš„è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹å·¥å…·ï¼Œç±»ä¼¼äº Valgrind

2. **å†…å­˜è¶Šç•Œæ£€æµ‹ï¼ˆOut-of-Boundsï¼‰**ï¼š
   - æ¼”ç¤ºå½“çº¿ç¨‹ç´¢å¼•è¶…å‡ºåˆ†é…çš„å†…å­˜èŒƒå›´æ—¶çš„è¡Œä¸º
   - `oob_kernel` ä¸­ï¼Œå½“ `idx == n` æ—¶å‘ç”Ÿè¶Šç•Œå†™å…¥
   - Memcheck èƒ½å¤Ÿç²¾ç¡®å®šä½è¶Šç•Œè®¿é—®çš„ä½ç½®å’Œçº¿ç¨‹ç´¢å¼•

3. **æ•°æ®ç«äº‰æ£€æµ‹ï¼ˆRace Conditionï¼‰**ï¼š
   - æ¼”ç¤ºå¤šä¸ªçº¿ç¨‹åŒæ—¶è¯»å†™ Shared Memory åŒä¸€åœ°å€çš„é—®é¢˜
   - `race_kernel` ä¸­ï¼Œæ‰€æœ‰çº¿ç¨‹åŒæ—¶æ‰§è¡Œ `s_val += 1`ï¼Œç»“æœæœªå®šä¹‰
   - Racecheck èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ç§ç«äº‰æ¡ä»¶ï¼Œå¹¶æŠ¥å‘Šå†²çªçš„çº¿ç¨‹

4. **éæ³•åŒæ­¥æ£€æµ‹ï¼ˆIllegal Synchronizationï¼‰**ï¼š
   - æ¼”ç¤ºåœ¨åˆ†æ”¯å‘æ•£åŒºåŸŸè°ƒç”¨ `__syncthreads()` çš„é—®é¢˜
   - `illegal_sync_kernel` ä¸­ï¼Œåªæœ‰ä¸€åŠçº¿ç¨‹èƒ½åˆ°è¾¾åŒæ­¥ç‚¹ï¼Œå¯¼è‡´æ­»é”
   - Synccheck èƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ç§éæ³•åŒæ­¥ï¼Œå¹¶æŠ¥å‘Šå‘æ•£çš„åˆ†æ”¯

#### è¿è¡Œæ–¹å¼

```bash
# ç›´æ¥è¿è¡Œï¼ˆä¼šè§¦å‘é”™è¯¯ï¼Œä½†å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™ï¼‰
./bin/01_cuda_basics_09_debug_and_sanitizer 0  # Out-of-Bounds
./bin/01_cuda_basics_09_debug_and_sanitizer 1  # Race Condition
./bin/01_cuda_basics_09_debug_and_sanitizer 2  # Illegal Sync

# ä½¿ç”¨ Sanitizer æ£€æµ‹ï¼ˆæ¨èï¼‰
cd examples/01_cuda_basics
bash 09_run_sanitizer.sh
```

#### é¢„æœŸè¾“å‡ºï¼ˆä½¿ç”¨ Sanitizerï¼‰

```shell
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (19,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (21,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (23,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (25,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (27,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (29,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
========= Barrier error detected. Divergent thread(s) in warp.
=========     at illegal_sync_kernel(int *)+0xa0 in 09_debug_and_sanitizer.cu:61
=========     by thread (31,0,0) in block (0,0,0)
=========     Saved host backtrace up to driver entry point at kernel launch time
=========         Host Frame: main [0x1754] in 01_cuda_basics_09_debug_and_sanitizer
=========
CUDA Error: unspecified launch failure at /data/AI-System-Performance-Lab/examples/01_cuda_basics/09_debug_and_sanitizer.cu:104
========= Target application returned an error
========= ERROR SUMMARY: 16 errors

Done. Analyze the output above to find the bugs.
```

#### è°ƒè¯•å·¥å…·

é¡¹ç›®æä¾›äº† `09_run_sanitizer.sh` è„šæœ¬ï¼Œè‡ªåŠ¨è¿è¡Œä¸‰ç§ Sanitizer å·¥å…·ï¼š

```bash
cd examples/01_cuda_basics
bash 09_run_sanitizer.sh
```

**æ³¨æ„**ï¼š
- è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰
- **éœ€è¦å®‰è£… CUDA Toolkit**ï¼ˆCompute Sanitizer éš CUDA Toolkit ä¸€èµ·å®‰è£…ï¼‰
- è„šæœ¬ä¼šä¾æ¬¡è¿è¡Œä¸‰ç§æ£€æµ‹å·¥å…·ï¼Œè¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **è‡ªåŠ¨è¿è¡Œ Memcheck**ï¼šæ£€æµ‹å†…å­˜è¶Šç•Œå’Œæ³„æ¼
- **è‡ªåŠ¨è¿è¡Œ Racecheck**ï¼šæ£€æµ‹æ•°æ®ç«äº‰
- **è‡ªåŠ¨è¿è¡Œ Synccheck**ï¼šæ£€æµ‹éæ³•åŒæ­¥

#### æŠ€æœ¯ç»†èŠ‚

- **Compute Sanitizer**ï¼šCUDA 11.0+ æä¾›çš„è¿è¡Œæ—¶é”™è¯¯æ£€æµ‹å·¥å…·
- **å†…å­˜è¶Šç•Œ**ï¼šå¯èƒ½å¯¼è‡´ç¨‹åºå´©æºƒæˆ–æ•°æ®æŸåï¼Œä½†æœ‰æ—¶å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™
- **æ•°æ®ç«äº‰**ï¼šç»“æœæœªå®šä¹‰ï¼Œå¯èƒ½å¯¼è‡´éš¾ä»¥è°ƒè¯•çš„ Bug
- **éæ³•åŒæ­¥**ï¼šä¼šå¯¼è‡´æ­»é”æˆ–æœªå®šä¹‰è¡Œä¸ºï¼ŒSynccheck èƒ½å¤Ÿæ£€æµ‹åˆ°

#### æ³¨æ„äº‹é¡¹

- Compute Sanitizer ä¼šæ˜¾è‘—é™ä½ç¨‹åºæ€§èƒ½ï¼ˆé€šå¸¸æ…¢ 10-100 å€ï¼‰ï¼Œä»…ç”¨äºè°ƒè¯•
- æŸäº›é”™è¯¯ï¼ˆå¦‚å¼‚æ­¥é”™è¯¯ï¼‰å¯èƒ½ä¸ä¼šç«‹å³æŠ¥é”™ï¼Œéœ€è¦ç­‰å¾…åŒæ­¥ç‚¹
- å»ºè®®åœ¨å¼€å‘é˜¶æ®µå®šæœŸä½¿ç”¨ Sanitizer æ£€æŸ¥ä»£ç 
- Windows ç¯å¢ƒä¸‹ Compute Sanitizer åŠŸèƒ½æœ‰é™ï¼Œå»ºè®®åœ¨ Linux/WSL ç¯å¢ƒä¸­ä½¿ç”¨

---

### ç¬¬ 10 ç« ï¼šæ€§èƒ½å»ºæ¨¡ç¬¬ä¸€æ€§åŸç† (`10_roofline_demo.cu`)

**Roofline Empirical Prober**ï¼šå®æµ‹ç¡¬ä»¶çš„å¸¦å®½æé™ï¼ˆBandwidthï¼‰ä¸ç®—åŠ›æé™ï¼ˆFLOPsï¼‰ï¼Œæ„å»º Roofline æ€§èƒ½æ¨¡å‹ã€‚

#### æ ¸å¿ƒçŸ¥è¯†ç‚¹

1. **Roofline æ¨¡å‹åŸºç¡€**ï¼š
   - **å¸¦å®½æé™ï¼ˆMemory Boundï¼‰**ï¼šå½“ Arithmetic Intensity (AI) è¾ƒä½æ—¶ï¼Œæ€§èƒ½å—é™äºå†…å­˜å¸¦å®½
   - **ç®—åŠ›æé™ï¼ˆCompute Boundï¼‰**ï¼šå½“ AI è¾ƒé«˜æ—¶ï¼Œæ€§èƒ½å—é™äºè®¡ç®—èƒ½åŠ›
   - **Roofline æ›²çº¿**ï¼šæè¿°ä¸åŒ AI å€¼ä¸‹çš„æ€§èƒ½ä¸Šé™ï¼Œå¸®åŠ©è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

2. **å¸¦å®½æµ‹è¯•ï¼ˆBandwidth Kernelï¼‰**ï¼š
   - ä½¿ç”¨ `float4` å‘é‡åŒ–è¯»å†™ï¼Œç”Ÿæˆ 128-bit LDG/STG æŒ‡ä»¤ï¼Œæœ€å¤§åŒ–æ€»çº¿åˆ©ç”¨ç‡
   - Grid-Stride Loop æ¨¡å¼ï¼Œç¡®ä¿æ‰€æœ‰çº¿ç¨‹éƒ½æœ‰å·¥ä½œ
   - AI = 0ï¼ˆçº¯å†…å­˜æ‹·è´ï¼Œæ— è®¡ç®—ï¼‰ï¼Œç”¨äºæµ‹è¯•å†…å­˜å¸¦å®½ä¸Šé™
   - æ•°æ®è§„æ¨¡è¶³å¤Ÿå¤§ï¼ˆ64MBï¼‰ï¼Œé¿å¼€ L2 Cacheï¼Œç›´æ¥æµ‹è¯• HBM å¸¦å®½

3. **ç®—åŠ›æµ‹è¯•ï¼ˆCompute Kernelï¼‰**ï¼š
   - ä½¿ç”¨å¯„å­˜å™¨çº§ FMAï¼ˆFused Multiply-Addï¼‰å¯†é›†è®¡ç®—
   - 4 æ¡ç‹¬ç«‹çš„æŒ‡ä»¤æµï¼ˆILPï¼‰ï¼Œå¡«æ»¡æµæ°´çº¿
   - æé«˜çš„ AI å€¼ï¼Œç¡®ä¿ç“¶é¢ˆå®Œå…¨åœ¨ ALU
   - `#pragma unroll` å±•å¼€å¾ªç¯ï¼Œå‡å°‘åˆ†æ”¯æŒ‡ä»¤å æ¯”

4. **ç†è®ºå³°å€¼è®¡ç®—**ï¼š
   - **å¸¦å®½å³°å€¼**ï¼šMemory Clock Ã— Bus Width Ã— 2 (DDR) / 8
   - **ç®—åŠ›å³°å€¼**ï¼šSM Clock Ã— SMs Ã— Cores/SM Ã— 2 (FMA) / 1e9
   - æ³¨æ„ï¼šCUDA 12+ ä¸­ `clockRate` å’Œ `memoryClockRate` å­—æ®µå·²ç§»é™¤ï¼Œéœ€è¦ä½¿ç”¨ NVML API è·å–å‡†ç¡®å€¼

#### é¢„æœŸè¾“å‡º

```
----------------------------------------------------------------
[Theoretical Peaks] Device: NVIDIA GeForce RTX 5090 (SMs: 170)
  > Memory Clock      : N/A (removed in CUDA 12+, using estimate: 1.00 GHz)
  > Memory Bus Width  : 512-bit
  > Peak Bandwidth    : 128.00 GB/s (Estimated, use NVML for accurate value)
  > SM Clock          : N/A (removed in CUDA 12+, using estimate: 1.50 GHz)
  > Peak FP32 Compute : 65.28 TFLOPS (Estimated)
  > Note              : For accurate clock rates, use NVML API
----------------------------------------------------------------

[Micro-Bench 1] Measuring HBM Bandwidth...
  > Achieved Bandwidth: 2087.03 GB/s

[Micro-Bench 2] Measuring FP32 Compute Peak...
  > Achieved Compute  : 87.20 TFLOPS
```

#### æ€§èƒ½åˆ†æå·¥å…·

é¡¹ç›®æä¾›äº† `10_profile_roofline.sh` è„šæœ¬ï¼Œä½¿ç”¨ Nsight Compute è¿›è¡Œ Roofline åˆ†æï¼š

```bash
cd examples/01_cuda_basics
bash 10_profile_roofline.sh
```

**æ³¨æ„**ï¼š
- è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹æ„å»ºç›®å½•ï¼ˆæ”¯æŒ Windows/CLion å’Œ Linux ä¸¤ç§æ„å»ºæ–¹å¼ï¼‰
- **éœ€è¦å®‰è£… Nsight Compute**ï¼ˆéš CUDA Toolkit ä¸€èµ·å®‰è£…ï¼‰
- è„šæœ¬ä¼šç”Ÿæˆ `.ncu-rep` æ–‡ä»¶ï¼Œéœ€è¦åœ¨ Nsight Compute GUI ä¸­æ‰“å¼€

è¯¥è„šæœ¬å¯ä»¥ï¼š
- **è‡ªåŠ¨è¿è¡Œ Roofline åˆ†æ**ï¼šä½¿ç”¨ `--set roofline` æ”¶é›† Roofline æ•°æ®
- **ç”Ÿæˆ Roofline å›¾è¡¨**ï¼šåœ¨ Nsight Compute GUI ä¸­å¯è§†åŒ–æ€§èƒ½ç“¶é¢ˆ
- **è¯†åˆ«æ€§èƒ½è¾¹ç•Œ**ï¼šè§‚å¯Ÿ Memory Bound å’Œ Compute Bound ä¸¤ä¸ªç‚¹
```shell
Using binary: /data/AI-System-Performance-Lab/build/bin/01_cuda_basics_10_roofline_demo

==========================================================
   Profiling Roofline with Nsight Compute (ncu)
==========================================================
Output: roofline_report.ncu-rep

==ERROR== unrecognised option '--output'. Use --help for further details.

==========================================================
Done!
Please open 'roofline_report.ncu-rep' in Nsight Compute GUI.
You will see two dots on the chart:
  1. One hitting the sloped ceiling (Memory Bound)
  2. One hitting the flat ceiling (Compute Bound)
==========================================================
```
#### æŠ€æœ¯ç»†èŠ‚

- **Arithmetic Intensity (AI)**ï¼šè®¡ç®—é‡ä¸æ•°æ®é‡çš„æ¯”å€¼ï¼Œå•ä½æ˜¯ FLOPs/Byte
- **Grid-Stride Loop**ï¼šç¡®ä¿æ‰€æœ‰çº¿ç¨‹éƒ½æœ‰å·¥ä½œï¼Œå³ä½¿ Grid å¤§å°å°äºæ•°æ®è§„æ¨¡
- **FMA æŒ‡ä»¤**ï¼šèåˆä¹˜åŠ æŒ‡ä»¤ï¼Œæ¯ä¸ªå‘¨æœŸå¯ä»¥æ‰§è¡Œä¸€æ¬¡ä¹˜æ³•å’Œä¸€æ¬¡åŠ æ³•
- **ILP (Instruction Level Parallelism)**ï¼šæŒ‡ä»¤çº§å¹¶è¡Œï¼Œé€šè¿‡ç‹¬ç«‹çš„æŒ‡ä»¤æµå¡«æ»¡æµæ°´çº¿

#### æ³¨æ„äº‹é¡¹

- æ•°æ®è§„æ¨¡éœ€è¦è¶³å¤Ÿå¤§ï¼ˆå»ºè®® â‰¥ 64MBï¼‰ï¼Œä»¥é¿å¼€ L2 Cache çš„å½±å“
- ç†è®ºå³°å€¼è®¡ç®—éœ€è¦å‡†ç¡®çš„æ—¶é’Ÿé¢‘ç‡ï¼ŒCUDA 12+ éœ€è¦ä½¿ç”¨ NVML API
- Roofline æ¨¡å‹æ˜¯æ€§èƒ½ä¼˜åŒ–çš„æŒ‡å¯¼å·¥å…·ï¼Œå¸®åŠ©è¯†åˆ«ç“¶é¢ˆå¹¶æŒ‡å¯¼ä¼˜åŒ–æ–¹å‘
- å®æµ‹å€¼é€šå¸¸ä¼šä½äºç†è®ºå³°å€¼ï¼Œå› ä¸ºå®é™…ä»£ç å­˜åœ¨å„ç§å¼€é”€ï¼ˆè°ƒåº¦ã€åŒæ­¥ç­‰ï¼‰

---

## ğŸ”§ å·¥å…·è„šæœ¬

- `01_fatbin_inspect.sh`ï¼šäºŒè¿›åˆ¶æ–‡ä»¶åˆ†æå·¥å…·ï¼Œç”¨äºæŸ¥çœ‹ PTX å’Œ SASS ä»£ç 
- `05_inspect_asm.sh`ï¼šSASS æ±‡ç¼–åˆ†æå·¥å…·ï¼Œç”¨äºéªŒè¯å‡½æ•°å†…è”è¡Œä¸º
- `07_inspect_sass.sh`ï¼šSASS å†…å­˜åˆ†æå·¥å…·ï¼Œç”¨äºæ£€æµ‹ Local Memory Spilling å’Œ `__restrict__` ä¼˜åŒ–æ•ˆæœ
- `08_profile_nsys.sh`ï¼šæ€§èƒ½åˆ†æè„šæœ¬ï¼ˆLinux/WSL ä¸“ç”¨ï¼‰ï¼Œä½¿ç”¨ Nsight Systems åˆ†æå¼‚æ­¥æµæ°´çº¿æ€§èƒ½
- `09_run_sanitizer.sh`ï¼šè°ƒè¯•å·¥å…·è„šæœ¬ï¼Œä½¿ç”¨ Compute Sanitizer æ£€æµ‹å†…å­˜è¶Šç•Œã€æ•°æ®ç«äº‰å’Œéæ³•åŒæ­¥
- `10_profile_roofline.sh`ï¼šæ€§èƒ½åˆ†æè„šæœ¬ï¼ˆLinux/WSL ä¸“ç”¨ï¼‰ï¼Œä½¿ç”¨ Nsight Compute è¿›è¡Œ Roofline æ€§èƒ½å»ºæ¨¡

## ğŸ“ æ³¨æ„äº‹é¡¹

- æ‰€æœ‰ç¤ºä¾‹ä»£ç éµå¾ª CUDA 12+ è§„èŒƒ
- ä»£ç åŒ…å«å®Œæ•´çš„é”™è¯¯æ£€æŸ¥æœºåˆ¶
- æ”¯æŒ Windows å’Œ Linux å¹³å°
- å…¼å®¹ CUDA 12.0+ ç‰ˆæœ¬ï¼ˆéƒ¨åˆ†å­—æ®µåœ¨ CUDA 12+ ä¸­å·²ç§»é™¤ï¼Œä½¿ç”¨æ¡ä»¶ç¼–è¯‘å¤„ç†ï¼‰
